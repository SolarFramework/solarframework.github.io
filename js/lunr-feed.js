// builds lunr
var index = lunr(function () {
  this.field('title')
  this.field('content', {boost: 10})
  this.ref('id')
});



index.add({
    title: "API",
    content: "API\n\nTable of Contents\n\nsubmenuconfig\nSolAR API\n\n\n\nsubmenuconfig\n\n\n\n\n\nSolAR API\n\n\n\n",
    id: 0
  });
  

index.add({
    title: "Community",
    content: "Community\n\nTODO\n\n\nPlease use slack to comunicate with the SolAR comunity\n\n\ncontribute SolAR Framework\n\n\n",
    id: 1
  });
  

index.add({
    title: "Contribute",
    content: "\nTable of Contents\n\nsubmenuconfig\nContribute\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nContribute\n\n\nThere are several ways to contribute to SolAR framework.\n\n\nYou can :\n\n\n\n\ncontribute to Core framework, by defining API, architecture, framework tools &#8230;&#8203; this typically needs software engineering and architecture skills.\n\n\ncontribute to Components, by creating a new SolAR component, that can be used in a pose estimation solution&#8230;&#8203; this typically needs computer vision skills (and software skills).\n\n\n\n\nTo know more about it works, please refer to the how it works section.\n\n\nPlease feel free to contact us !\n\n\nPlease contribute !\n\n\n",
    id: 2
  });
  

index.add({
    title: "Discover",
    content: "\nTable of Contents\n\nsubmenuconfig\nDiscover Solar\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nDiscover Solar\n\n\nSolAR is an open-source framework released under Apache license 2.0 making it possible to easily create your own camera pose estimation solution to develop augmented reality applications.\n\n\n\n\nYour browser does not support the video tag.\n\n\n\n\n",
    id: 3
  });
  

index.add({
    title: null,
    content: "\n\n  \n    SolAR\n    SolAR\n    https://solarframework.github.io//\n    \n    Mon, 22 Jan 2018 09:59:12 +0000\n    Mon, 22 Jan 2018 09:59:12 +0000\n    Jekyll v3.5.1\n    \n  \n\n",
    id: 4
  });
  

index.add({
    title: "welcome",
    content: "SolAR, Solution for Augmented Reality\n\n\n\n\n\n\nyou will find information about SolAR in the following sections\n\n\n\n\nDiscover will give you general information about the SolAR Framework project\n\n\nUse it explains how to use SolAR framework quickly, and more in depth for experts or future contributors\n\n\nContribute will give information for all SolAR contributors, as SolAR is open-source\n\n\nAPI will be helpful for all SolAR developers : contributors and users.\n\n\n\n\nBy using SolAR, you can easily build augmented reality applications by testing different vision based localization solutions, create and share your own camera pose estimation pipeline with the community, and even develop efficient low-level processing elements to meet specific requirements.\n\n\nSolAR is a framework that improves interoperability for augmented reality applications and offers efficiency and robustness thanks to a modular software pipeline architecture.\n",
    id: 5
  });
  

index.add({
    title: "Knowledge",
    content: "Knowledge\n\nsubmenuconfig\n\n\n\n\n\nTODO\n\n\n\n",
    id: 6
  });
  

index.add({
    title: null,
    content: "// builds lunr\nvar index = lunr(function () {\n  this.field('title')\n  this.field('content', {boost: 10})\n  this.ref('id')\n});\n\n{% assign count = 0 %}\n{% for page in site.pages %}\nindex.add({\n    title: {{page.title | jsonify}},\n    content: {{page.content | strip_html | jsonify}},\n    id: {{count}}\n  });\n  {% assign count = count | plus: 1 %}\n{% endfor %}\n\n\n{% for collection in site.collections %}\n  {% assign name = collection.label %}\n  {% assign sorted_pages = site[name] | sort:\"weight\" %}\n  {% for page in sorted_pages %}\n\n    index.add({\n      title: {{page.title | jsonify}},\n      content: {{page.content | strip_html | jsonify}},\n      id: {{count}}\n    });\n    {% assign count = count | plus: 1 %}\n\n  {% endfor %}\n{% endfor %}\n\n\nvar store = [];\n{% for page in site.pages %}\n  {% capture link %}{{ site.url }}{{ site.baseurl }}{{ page.url }}{% endcapture %}\nstore.push({\"title\": {{page.title | jsonify}},\n  \"link\": {{ link | jsonify }}\n});\n{% endfor %}\n\n{% for collection in site.collections %}\n  {% assign name = collection.label %}\n  {% assign sorted_pages = site[name] | sort:\"weight\" %}\n  {% for page in sorted_pages %}\n    {% capture link %}{{ site.url }}{{ site.baseurl }}{{ page.url }}{% endcapture %}\n    store.push({\"title\": {{page.title | jsonify}},\n      \"link\": {{ link | jsonify }}\n    });\n  {% endfor %}\n{% endfor %}\n\nfunction searchAndDisplay(query){\n  var resultdiv = $('#results');\n  var result = index.search(query);\n  // Show results\n  resultdiv.empty();\n  // Add status\n  resultdiv.prepend('Found '+result.length+' result(s)');\n  // Loop through, match, and add results\n  for (var item in result) {\n    var ref = result[item].ref;\n    var searchitem = ''+store[ref].title+'';\n    resultdiv.append(searchitem);\n  }\n}\n\n// builds search\n$(document).ready(function() {\n    var query = (decodeURI(location.search).split(\"q\" + '=')[1] || '').split('&')[0];\n    var formattedQuery = query.split(\"+\").join(\" \");\n    searchAndDisplay(formattedQuery);\n\n    $('input#search').on('keyup', function () {\n      var query = $(this).val();\n      searchAndDisplay(query);\n    });\n});\n",
    id: 7
  });
  

index.add({
    title: "Made with SolAR",
    content: ":page-layout: _auto\n= Made with SolAR\n:showtitle:\n:page-title: Made with SolAR\n:page-description: Made with SolAR\n:page-liquid:\n\nTo be done\n",
    id: 8
  });
  

index.add({
    title: "package &amp; download third parties",
    content: ":page-layout: _auto\n= package & download third parties\n\n\n== packaging\n\n. clone the following git repository:\ngit clone ssh://gitolite@forge.b-com.com/bcom-templates/builddefs/builddefs-scripts.git\n\n\nStarting from a fresh installed package (ie. result of a \"make install\"), run\nthe following perl script (under builddefs-scripts/xplatform)\n\n  $ bcom-packager.pl\n----\n  OPTIONS:\n      -s, --sourcedir                  => product root directory (where libs and includes are located)\n      -o, --osname                     => specify the operating system targeted by the product build. It is one of [win|mac|linux]. (defaults to the current OS environment)\n      -i, --includedir                 => relative path to include folder to export (defaults to the sourcedir provided with -s)\n      -l, --libdir                     => relative path to the library folder to export (defaults to the sourcedir provided with -s)\n      -r, --redistfile                 => relative path and filename of a redistribution file to use (such as redist.txt intel ipp's file). Only listed libraries in this file will be packaged\n      -d, --destinationdir             => package directory root destination (where the resulting packaging will be stored)\n      -p, --packagename                => package name\n      -v, --packageversion             => package version\n      -n, --ignore-mode                => forces the pkg-config generated file to ignore the mode when providing -L flags\n      -m, --mode [debug|release]       => specify the current product build mode. Binaries will be packaged in the appropriate [mode] folder\n      -a, --architecture [x86_64|i386] => specify the current product build architecture. Binaries will be packaged in the appropriate [architecture] folder\n      -w, --withsuffix suffix          => specify the suffix used by the thirdparty when building with mode mode\n      -u, --useOriginalPCfiles         => specify to search and use original pkgconfig files from the thirdparty, instead of generating them\n      -h, --help                       => display this help\n\n  EXAMPLES:\n      -s {path_to_root_sourcedir} --o win d {path_to_destination_dir} -p intel-tbb -v 2017.5 -l build/macos_intel64_clang_cc8.0.0_os10.11.6_release -m release -i include\n\n----\n\n. Use the artifactory packager scripts.\n\nUnder windows, use *builddefs-scripts/win/artiPackager.bat*\n\nUnder linux, use *builddefs-scripts/unixes/artiPackager.sh*\n\nUsage: run the .bat / .sh scripts where the packages are.\n\n== Using pkgm-bcom\n\n. Source: https://forge.b-com.com/www/bcom-templates//tools/pkgm-bcom-index/\n. You must have java installed on your machine: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n. You will need to create an artifactory API_KEY: http://repository.b-com.com/webapp/#/profile\n. Download pkgm-bcom tool here: http://repository.b-com.com/bcom-devtools-generic-local/pkgm-bcom/1.0.0/multi/pkgm-1.0.0-fat.jar\n. In order to download dependencies described in a packagedependencies.txt file, you will need to launch:\n\n    java -jar [path to]/pkgm-1.0.0-fat.jar install -a x86_64 -c release -m shared -f packagedependencies.txt -k [YOUR artifactory API KEY]\n\n. NB: this will work only if third parties are available on artifactory repository\n\nFor example packagedependencies.txt can include the two following lines:\n\n  opencv|3.2.0|opencv|thirdParties|http://repository.b-com.com/argo-generic\n  boost|1.64.0|boost|thirdParties|http://repository.b-com.com/argo-generic\n",
    id: 9
  });
  

index.add({
    title: "Search",
    content: "Search results : \n\n\n",
    id: 10
  });
  

index.add({
    title: "Tags",
    content: "Tags\n\n{% capture site_tags %}{% for tag in site.tags %}{{ tag | first }}{% unless forloop.last %},{% endunless %}{% endfor %}{% endcapture %}\n\n\n{% assign tag_words = site_tags | split:',' | sort %}\n\n\n\n\n\n  {% for item in (0..site.tags.size) %}{% unless forloop.last %}\n    {% capture this_word %}{{ tag_words[item] }}{% endcapture %}\n    \n      {{ this_word }}\n        ({{ site.tags[this_word].size }})\n      \n    \n  {% endunless %}{% endfor %}\n\n\n\n\n  {% for item in (0..site.tags.size) %}{% unless forloop.last %}\n    {% capture this_word %}{{ tag_words[item] }}{% endcapture %}\n    {{ this_word }}\n    {% for post in site.tags[this_word] %}{% if post.title != null %}\n      \n        \n          {{ post.title }}\n        \n        \n          {{ post.date | date_to_string }}\n        \n      \n      \n    {% endif %}{% endfor %}\n  {% endunless %}{% endfor %}\n\n",
    id: 11
  });
  

index.add({
    title: "Use it",
    content: ":page-layout: _auto\n= Use it !\n:showtitle:\n:page-title: Use it\n:page-description: Use it\n:page-layout: default\n:page-category: use_it\n:page-liquid:\n:toc:\n\n\n== submenuconfig\n\n[none]\n{% for collection in site.collections %}\n  {% assign name = collection.label %}\n  {% if name == page.categories[0] %}\n\n\t  {% assign sorted_subparts = site[name] | sort:\"weight\" %}\n\t  {% for subpart in sorted_subparts %}\n\t    {% assign page_level = subpart.url | split:'/' %}\n\n\t\t{% if page_level.size == 3 %}\n\t\t\t{% assign subpart_url = subpart.url | remove_first:'/' %}\n* {{ site.url }}{{ site.baseurl }}{{ subpart_url }}[{{ subpart.title }}]\n\t\t{% endif %}\n\t  {% endfor %}\n\t  {% break %}\n  \n  {% endif %}\n{% endfor %}\n\n\n== Please contribute\n\n//include::_opensource.adoc[]\n\nSolAR framework is *looking for contributors* .\n\n== How to use\n\n\nYou can start using SolAR Framework very quickly:\n\n* download and execute the SolAR installer. It will install all you need to user SolAR Framework. link:downloads[*binaries*].  It will only take 15 minutes .\n\n* download and test solAR sample code :samples[*sample codes*], compile it and run it. You will learn about SolARFramework use (code organization, API call) . It will take about 30 minutes.\n\n* implement your own program based on SolAR: to help you some tutorials will soon be available.\n link:tutorials[*tutorials*] and do some exercises. You will learn more about SolARFramework, so that you will be able to program a code based on SolAR framework by your own. \n //It will take more time, depending on which level of expertise you want. \n//this step is needed if you want to be able to contribute to SolAR.\n\n\n== who \n\nSOlAR framework can be used by :\n\n* pose estimation developers (using a C++ API) and \n* designers (using an editor), \n\nto create a good pose estimation solution.\n\n//It can be used  by the developer of AR application in their IDE.\n\n\n",
    id: 12
  });
  




  
  
  

  
  
  

    index.add({
      title: "Acquisition",
      content: "\nThe Acquisition Interface manages the capturing strategy from a given device and provides the input signal to the next processing component.\n\n\nImage\n\nThe ISolARCamera interface is dedicated to acquiring images from external device. It allows grabbing the current image and sets/extracts some parameters related to the projection and acquisition models as follows:\n\n\n\n\nget/set camera acquisition parameters: get default acquisition setting parameters (image size, frame rate..). The user can also set custom parameters which force the camera grabbing parameters to that value.\n\n\nget/set camera projection parameters: get camera projection parameters including camera matrix and distortion parameters. It assumes that camera is already correctly calibrated. The user can set these parameters by performing a preliminary calibration.\n\n\n\n",
      id: 13
    });
    

  

    index.add({
      title: "Conversion",
      content: "\nThe Conversion Interface manages conversion for different data structure.\n\n\nImage\n\nThe ISolaARImageConvertor performs the conversion between several image formats. It allows converting both color and type value using one unified method which automatically detects the color and/or type layers of the input and output.\n\n",
      id: 14
    });
    

  

    index.add({
      title: "Estimation",
      content: "\nThe Estimation Interface manages several pose estimation methods for cameras, objects and markers.\n\n\nFeatures\n\nThe ISolARKeypointDetector, ISolARDescriptorExtractor and ISolARDescriptorMatcher allow to detect geometrically relevant points in the image using known algorithms such as SURF or SIFT. (SURF, SIFT..). They also compute descriptors around these points and correlate sets of matches.\n\n\nThe ISolARHomographyFinder performs an homography transformation estimation and extracts a camera pose.\n\n\n\nMarker\n\nThe ISolARMarkerFinder allows to perform marker finding operations on different types of markers. It detects, segments and recognizes the marker and estimates its pose relative to the camera.\n\n",
      id: 15
    });
    

  

    index.add({
      title: "Features",
      content: "\nExtraction\n\nToDo\n\n\n\nDescription\n\nToDo\n\n\n\nMatching\n\nToDo\n\n",
      id: 16
    });
    

  

    index.add({
      title: "Filtering",
      content: "\nThe Filtering Interface manages filtering operations for different data structure.\n\n\nImage\n\nThe ISolARImageFilter is dedicated to perform various filtering operations assuming input/output consistency. The interface embeds the following operations:\n\n\n\n\nBinarizing\n\n\nEqualizing\n\n\nBlurring\n\n\nErosion\n\n\nDilation\n\n\nGradient\n\n\nLaplacian\n\n\n\n\n\nFeatures\n\nThe ISolARFeaturesFilter is dedicated to filter different extracted/computed features.\n\n\n\nMarkers\n\nThe ISolARMarkerFilter is dedicated to enhance marker filtering.\n\n",
      id: 17
    });
    

  

    index.add({
      title: "Image",
      content: "\nCamera\n\nToDo\n\n\n\nImage conversion\n\nToDo\n\n\n\nImage filters\n\nToDo\n\n",
      id: 18
    });
    

  

    index.add({
      title: "Optimization",
      content: "\nExtraction\n\nToDo\n\n\n\nDescription\n\nToDo\n\n\n\nMatching\n\nToDo\n\n",
      id: 19
    });
    

  

    index.add({
      title: "Poseestimation",
      content: "\nToDo\n",
      id: 20
    });
    

  

    index.add({
      title: "Thirdpartyconnector",
      content: "\nThe SolAR third party connector is a special SolAR Component used to exchange internal SolAR pose data with any third party outside of the SolAR framework. It is used to safely provide access to a SolAR Image and its associated SolAR Pose in a thread safe race free fashion. It internally implements a mutex locked circular buffer, allowing safe producer/consumer access. It allows synchronous and asynchronous read access for the consumer.\n\n\n\n\n\n\n\nThe internal buffer size of the container is currently set at one which means only the latest image and pose are available to the consumer at any given time. In the near future, SolAR will allow users to provide initialization parameters when creating components so the users will be able to specify the size of the buffer they desire.\n\n\nProducer\n\nAny component wishing to expose its pose data to an external third party must use a Third Party Connector. It can then use the set method to set the current SolAR Image and its associated SolAR Pose. The set method is thread safe and blocking. It will not return until the lock on the internal buffer is released by the reader.\n\n\n\nConsumer\n\nAny third party external to SolAR that needs access to internal pose data of a component must connect to its Third Party Connector. It can then use either the get method or the tryGet method to get the latest SolARImage and its associated SolARPose. The get method is thread safe and blocking. This means it will not return until there is available data to read and the lock on the internal buffer is released by the writer. The tryGet method is also thread safe but non blocking. It will return immediately after being called. It will return true if it was able to acquire the lock and read the data, or false if it was unable to obtain the lock or if there was nothing to read.\n\n",
      id: 21
    });
    

  

    index.add({
      title: "Features",
      content: "\nThe current implementation of the SolAR Features data structure takes advantage of the OpenCV Features2D definition. However, we are currently working on an abstract API to handle multiple keypoints, features descriptors and extractors implementations using technologies such as CUDA and OpenVX. We will be especially focusing on proper memory management and avoiding useless data copying.\n\n\nThe current SolAR Features data structure is not the final implementation we are aiming for and will be undergoing changes as we actively work on it.\n",
      id: 22
    });
    

  

    index.add({
      title: "Image",
      content: "\nA SolAR image is an array of pixels where each pixel is defined by a set of color components coded with a given number of bits. Each pixel can be encoded with a dedicated colorimetric space (RGB, YUV, LAB, etc.). Contrary to OpenCV, an image is not just a matrix or an array. A SolAR image is clearly defined as an image object to ensure that a component waiting for an image as an input will not receive a random matrix such as a pose. Thus, an image is defined by:\n\n\n\n\nThe image size (width, height)\n\n\nThe image layout such as LAYOUT_GRB, LAYOUT_BGR, LAYOUT_GREY, LAYOUT_RGBA, LAYOUT_RGBX, LAYOUT_UNDEFINED\n\n\nThe pixel order either INTERLEAVED or PER_CHANNEL\n\n\nThe size of each color component, also called data type which can be either TYPE_8U, TYPE_16U, TYPE_32U, TYPE_64U\n\n\nA pointer to the raw data\n\n\n\n\nIn order to limit memory allocations and copies, which can drastically impact the efficiency of the camera pose estimation implementation, an image can point to the raw data instantiated by third party libraries such as OpenCV or OpenVX.\n",
      id: 23
    });
    

  

    index.add({
      title: "Markers",
      content: "\nA SolAR Marker is a structure describing a convex area in a SolAR Image. A SolAR Marker allows managing different types of markers such ad fiducial markers or checker boards. It encodes shape and pose information as follows:\n\n\n\n\nEdges: a set of SolARPoint_2Df defining the convex area. A fiducial marker can be described with four edges. The order of the points is important and impacts the structure of the marker\n\n\nTranslation: a SolARVector3f defining the translation of the marker relative to the camera\n\n\nRotation: a SolARRotationMatrixf  defining the rotation of the marker relative to the camera\n\n\n\n\nThe SolAR Marker embeds information about the marker in a minimalist way. The reason is directly linked to the desired genericity across all the existing markers in the state-of-the-art methods.\n",
      id: 24
    });
    

  

    index.add({
      title: "Matrix",
      content: "\nThe SolAR implementation of matrices is based on the open source Eigen library for linear algebra. The SolAR framework redefines the following matrices:\n\n\n\n\nSolARVector4f  equates to a 4x1 matrix of floats\n\n\nSolARVector4d  equates to a 4x1 matrix of doubles\n\n\nSolARVector3f  equates to a 3x1 matrix of floats\n\n\nSolARVector3d  equates to a 3x1 matrix of doubles\n\n\nSolARTranslationVectorf equates to a 3x1 matrix of floats used to define a translation\n\n\nSolARPoint_3Df equates to a 3x1 matrix of floats used to define a 3D point\n\n\nSolARPoint_2Df equates to a 2x1 matrix of floats used to define a 2D point\n\n\nSolARPoseMatrixf equates to a 4x4 matrix of floats used to define a pose\n\n\nSolARMatrix33d equates to a 3x3 matrix of doubles\n\n\nSolARRotationMatrixf equates to a 3x3 matrix of floats used to define a rotation\n\n\nSolARQuaternionf equates to a Quaternion in floats used to define a rotation\n\n\n",
      id: 25
    });
    

  

    index.add({
      title: "Pose",
      content: "\nThe SolaARPose data structure is based on a standard row major homogeneous 4x4 matrix. Euler angles and quaternions can be directly extracted from this structure built using Eigen algorithms.\n",
      id: 26
    });
    

  

    index.add({
      title: "how it works",
      content: "\nTable of Contents\n\nsubmenuconfig\nSolAR Overview\nSolAR Data Structures\nSolAR components interfaces\nSolAR components handling\nFrequently Asked Questions\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nSolAR Overview\n\n\nSolAR is a solution to easily and quickly implement custom camera pose estimation pipelines based on a set of vision and mathematics components in order to make them available to AR application developers.\n\n\nThe SolAR core handles everything that will allow the implementation of a pipeline:\n\n\n\n\nSolAR Data Structures define the information that flow in the pipelines and are exchanged between components.\n\n\nSolAR Components Interfaces define a standardized interface for the different categories of basic processing elements required to implement camera pose estimation (i.e.: key point extractor, descriptor computation, etc.). This unified interface is required to ensure interoperability between components allowing to easily swap one with another to improve the final camera pose estimation pipeline.\n\n\nThe SolAR Pipeline Manager handles the implementation of a pipeline by loading components, connecting them, and running the pipeline.\n\n\n\n\nThe SolAR Components are implementations of basic processing elements compliant with the SolAR components interfaces. Several components can implement the same component interface. In general, these components are created by wrapping computer vision libraries that could be either open-source (OpenCV, PCL, ROS, etc.) or proprietary. Each component can define its own parameters that will be used to fine tune the camera pose estimation solution.\n\n\n\n\n\n\n\n\n\nComing soon: configure components on the fly, pipeline, multithread, metadata.\n\n\n\n\n\n\nSolAR Data Structures\n\n\nThe SolAR pipeline consists of a chain of basic processing elements linked together so that the outputs of each element are the inputs of the next one. In order to provide modularity, SolAR specifies standard data structures defining the information exchanged between components required to implement a camera pose estimation solution.\n\n\nThe following categories describe the current SolAR data structures, with more to come.\n\n\nImage\n\nA SolAR image is an array of pixels where each pixel is defined by a set of color components coded with a given number of bits. Each pixel can be encoded with a dedicated colorimetric space (RGB, YUV, LAB, etc.). Contrary to OpenCV, an image is not just a matrix or an array. A SolAR image is clearly defined as an image object to ensure that a component waiting for an image as an input will not receive a random matrix such as a pose. Thus, an image is defined by:\n\n\n\n\nThe image size (width, height)\n\n\nThe image layout such as LAYOUT_GRB, LAYOUT_BGR, LAYOUT_GREY, LAYOUT_RGBA, LAYOUT_RGBX, LAYOUT_UNDEFINED\n\n\nThe pixel order either INTERLEAVED or PER_CHANNEL\n\n\nThe size of each color component, also called data type which can be either TYPE_8U, TYPE_16U, TYPE_32U, TYPE_64U\n\n\nA pointer to the raw data\n\n\n\n\nIn order to limit memory allocations and copies, which can drastically impact the efficiency of the camera pose estimation implementation, an image can point to the raw data instantiated by third party libraries such as OpenCV or OpenVX.\n\n\n\nMatrix\n\nThe SolAR implementation of matrices is based on the open source Eigen library for linear algebra. The SolAR framework redefines the following matrices:\n\n\n\n\nSolARVector4f  equates to a 4x1 matrix of floats\n\n\nSolARVector4d  equates to a 4x1 matrix of doubles\n\n\nSolARVector3f  equates to a 3x1 matrix of floats\n\n\nSolARVector3d  equates to a 3x1 matrix of doubles\n\n\nSolARTranslationVectorf equates to a 3x1 matrix of floats used to define a translation\n\n\nSolARPoint_3Df equates to a 3x1 matrix of floats used to define a 3D point\n\n\nSolARPoint_2Df equates to a 2x1 matrix of floats used to define a 2D point\n\n\nSolARPoseMatrixf equates to a 4x4 matrix of floats used to define a pose\n\n\nSolARMatrix33d equates to a 3x3 matrix of doubles\n\n\nSolARRotationMatrixf equates to a 3x3 matrix of floats used to define a rotation\n\n\nSolARQuaternionf equates to a Quaternion in floats used to define a rotation\n\n\n\n\n\nPose\n\nThe SolaARPose data structure is based on a standard row major homogeneous 4x4 matrix. Euler angles and quaternions can be directly extracted from this structure built using Eigen algorithms.\n\n\n\nMarker\n\nA SolAR Marker is a structure describing a convex area in a SolAR Image. A SolAR Marker allows managing different types of markers such ad fiducial markers or checker boards. It encodes shape and pose information as follows:\n\n\n\n\nEdges: a set of SolARPoint_2Df defining the convex area. A fiducial marker can be described with four edges. The order of the points is important and impacts the structure of the marker\n\n\nTranslation: a SolARVector3f defining the translation of the marker relative to the camera\n\n\nRotation: a SolARRotationMatrixf  defining the rotation of the marker relative to the camera\n\n\n\n\nThe SolAR Marker embeds information about the marker in a minimalist way. The reason is directly linked to the desired genericity across all the existing markers in the state-of-the-art methods.\n\n\n\nFeatures\n\nThe current implementation of the SolAR Features data structure takes advantage of the OpenCV Features2D definition. However, we are currently working on an abstract API to handle multiple keypoints, features descriptors and extractors implementations using technologies such as CUDA and OpenVX. We will be especially focusing on proper memory management and avoiding useless data copying.\n\n\nThe current SolAR Features data structure is not the final implementation we are aiming for and will be undergoing changes as we actively work on it.\n\n\n\n\n\nSolAR components interfaces\n\n\nSolAR components are vision or mathematics processing elements compliant with the SolAR component interface defined by the SolAR framework.\n\n\n\n\n\n\n\nAcquisition\n\nThe Acquisition Interface manages the capturing strategy from a given device and provides the input signal to the next processing component.\n\n\nImage\n\nThe ISolARCamera interface is dedicated to acquiring images from external device. It allows grabbing the current image and sets/extracts some parameters related to the projection and acquisition models as follows:\n\n\n\n\nget/set camera acquisition parameters: get default acquisition setting parameters (image size, frame rate..). The user can also set custom parameters which force the camera grabbing parameters to that value.\n\n\nget/set camera projection parameters: get camera projection parameters including camera matrix and distortion parameters. It assumes that camera is already correctly calibrated. The user can set these parameters by performing a preliminary calibration.\n\n\n\n\n\n\nConversion\n\nThe Conversion Interface manages conversion for different data structure.\n\n\nImage\n\nThe ISolaARImageConvertor performs the conversion between several image formats. It allows converting both color and type value using one unified method which automatically detects the color and/or type layers of the input and output.\n\n\n\n\nFiltering\n\nThe Filtering Interface manages filtering operations for different data structure.\n\n\nImage\n\nThe ISolARImageFilter is dedicated to perform various filtering operations assuming input/output consistency. The interface embeds the following operations:\n\n\n\n\nBinarizing\n\n\nEqualizing\n\n\nBlurring\n\n\nErosion\n\n\nDilation\n\n\nGradient\n\n\nLaplacian\n\n\n\n\n\nFeatures\n\nThe ISolARFeaturesFilter is dedicated to filter different extracted/computed features.\n\n\n\nMarkers\n\nThe ISolARMarkerFilter is dedicated to enhance marker filtering.\n\n\n\n\nEstimation\n\nThe Estimation Interface manages several pose estimation methods for cameras, objects and markers.\n\n\nFeatures\n\nThe ISolARKeypointDetector, ISolARDescriptorExtractor and ISolARDescriptorMatcher allow to detect geometrically relevant points in the image using known algorithms such as SURF or SIFT. (SURF, SIFT..). They also compute descriptors around these points and correlate sets of matches.\n\n\nThe ISolARHomographyFinder performs an homography transformation estimation and extracts a camera pose.\n\n\n\nMarker\n\nThe ISolARMarkerFinder allows to perform marker finding operations on different types of markers. It detects, segments and recognizes the marker and estimates its pose relative to the camera.\n\n\n\n\nSolAR Third Party Connector\n\nThe SolAR third party connector is a special SolAR Component used to exchange internal SolAR pose data with any third party outside of the SolAR framework. It is used to safely provide access to a SolAR Image and its associated SolAR Pose in a thread safe race free fashion. It internally implements a mutex locked circular buffer, allowing safe producer/consumer access. It allows synchronous and asynchronous read access for the consumer.\n\n\n\n\n\n\n\nThe internal buffer size of the container is currently set at one which means only the latest image and pose are available to the consumer at any given time. In the near future, SolAR will allow users to provide initialization parameters when creating components so the users will be able to specify the size of the buffer they desire.\n\n\nProducer\n\nAny component wishing to expose its pose data to an external third party must use a Third Party Connector. It can then use the set method to set the current SolAR Image and its associated SolAR Pose. The set method is thread safe and blocking. It will not return until the lock on the internal buffer is released by the reader.\n\n\n\nConsumer\n\nAny third party external to SolAR that needs access to internal pose data of a component must connect to its Third Party Connector. It can then use either the get method or the tryGet method to get the latest SolARImage and its associated SolARPose. The get method is thread safe and blocking. This means it will not return until there is available data to read and the lock on the internal buffer is released by the writer. The tryGet method is also thread safe but non blocking. It will return immediately after being called. It will return true if it was able to acquire the lock and read the data, or false if it was unable to obtain the lock or if there was nothing to read.\n\n\n\n\n\n\nSolAR components handling\n\n\nSolAR relies on the Cross Platform Component Framework (XPCF), a versatile framework that provides dynamic component instantiation and loading from modules. Basically, modules are libraries that collect components sharing a common element: purpose, framework, etc. XPCF also provides uniform component parametrization. Using XPCF, and thanks to the unified SolAR interfaces, it will be possible to build applications by picking and choosing different components in different modules at runtime without prior knowledge of the components when the application itself is compiled.\n\n\nFor more details, please refer to the XPCF website (coming soon).\n\n\n\n\nFrequently Asked Questions\n\n\n\n\nWhat is SolAR?\nSolAR is an open source initiative to develop a framework for pose estimation that can be used for Augmented Reality (AR) applications.\n\n\nWho initiated the SolAR project?\nThe b&lt;&gt;comInstitute of Research and Technology initiated the SolAR project after collecting the feedback of AR actors, AR end-users (industry, real-estate, medical, etc.), AR developers (essentially SMEs) and computer vision experts (academic researchers and research engineers from companies).\n\n\nWho can contribute to the SolAR project?\nAnyone can contribute to the SolAR project. Contributors only need to be proficient in C++ and computer vision skills.\n\n\nCan I use the SolAR framework for my AR applications?\nOf course! Just be wary of the licenses of the components used by the pose estimation pipelines you choose as each component can be under its own license, independently of the encompassing SolAR Apache v2 license.\n\n\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 27
    });
    

  

    index.add({
      title: "getting started",
      content: "\nTable of Contents\n\nsubmenuconfig\nGetting started\nInstall your IDE\nInstall and build SolAR Framework\nTest your first SolAR program\nUpdate and re-build SolAR\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nGetting started\n\n\n\n\n\nInstall your IDE\n\n\nLinux\n\nInstall your environment following these guidelines:\n(Ubuntu 16.04)\n\n\nInstall pre-requisites\n\nIn a console window, enter the following command:\n\n\n\n\n\nsudo apt-get install python3-pip unzip build-essential gdb git pkg-config default-jre libqt5core5a libgtk2.0-0 libwebp5 libjasper1 libopenexr22 libopenni0 libdc1394-22 libavcodec-ffmpeg56 libavutil-ffmpeg54 libavformat-ffmpeg56 libswscale-ffmpeg3\n\n\n\n\n\nAnd follow the instructions to complete the installation\n\n\n\nInstall QT Creator from QT installer\n\nDownload qt installer for Linux 64 bits here:\nhttp://download.qt.io/official_releases/qt/5.9/5.9.1/qt-opensource-linux-x64-5.9.1.run\n\n\nThen, just run the installer. For this, open a console window and enter the following command:\n\n\n$ cd ~/Downloads\n\n\n(English version)\n\n\nor\n\n\ncd ~/Téléchargements\n\n\n(French version)\n\n\nThen:\n\n\n\n$ chmod 755 qt-opensource-linux-x64-5.9.1.run\n$ sudo ./qt-opensource-linux-x64-5.9.1.run\n\n\n\n\nSet up environment variables\n\n\n\ncreate a BCOMDEVROOT directory on your local hard drive\n\n\nmkdir [path]/BCOMDEVROOT\nmkdir [path]/BCOMDEVROOT/linux\n\n\n\n\n\n\nAdd the following line into your ~/.profile file:\n\n\n\nexport BCOMDEVROOT= \"[path]/BCOMDEVROOT/linux\"\n\n\n\nAlso add the following line to your .bashrc file:\n\n\n\nexport PATH=/opt/Qt5.9.1/5.9/gcc_64/bin/:/opt/Qt5.9.1/Tools/QtCreator/bin/:$PATH\n\n\n\n\n\nWindows 7/10\n\nPre-requisites\n\nInstall pkgconfig, sourcetree, python3 and jre.\n\n\n\n\n\npkg-config\n\n\npkg-config is a helper tool used when compiling applications and libraries.\n\n\n\nDownload the setup program here:\nhttps://github.com/SolarFramework/binaries/releases/download/pkgconfig%2Fwin/Setup_pkg-config.exe\n\n\n\n\n\n\n\nSourcetree\n\n\nSourcetree is a free git client for windows and mac.\n\n\n\nDownload it on the following web site:\n https://www.sourcetreeapp.com/\nDuring Sourcetree installation, choose to download the embedded version of git program.\n\n\n\n\n\n\n\npython3\n\n\nPython is a widely used high-level programming language for general-purpose programming. Python3 is requiredby SolAR in order to create new components, based on templates.\n\n\n\nDownload the latest version of python3 for windows here:\nhttps://www.python.org/downloads/\n\n\n\n\n\n\n\njre\n\n\nJava Runtime Environment, or JRE, is required in order to download third parties libraries based on your environment.\n\n\n\nYou can download JRE here:\nhttp://www.oracle.com/technetwork/java/javase/downloads/jre8-downloads-2133155.html\n\n\n\n\n\n\n\n\nInstall Visual Studio\n\nYou can either install Visual Community 2015 (adapted for OpenSource) or install Visual Studio 2015.\n\n\n\n\n\n\n\n\n\nCheck Visual Studio C /C ++compiler is installed correctly\n\nCreate a new C++ project and follow steps advised by the prompt.\n\n\nIf the compiler is not installed, you will have an option to install it right from the new project window.\n\n\nYou should verify you are able to run a console application \"hello world\" in C++.\n\n\n\n\n\n\n\n\nInstall QT creator\n\nInstall QT community by downloading and launching the following file:\n\n\n\nhttp://download.qt.io/official_releases/online_installers/qt-unified-windows-x86-online.exe\n\n\n\nDuring installation choose a minimal QT 5.9.0 with msvc2015 64bits, and QT Tools→QT creator (default selection) only\n\n\nCheck your QT configuration\n\nOpen the \"tools/options\" window and section \"build and run\"; please check compiler and debugger is installed. Every tab should be filled in.\n\n\n\n\nCompiler\n\n\n\n\n\n\n\n\n\n\n\nDebugger\n\n\n\n\n\n\n\n\n\nIf not, make sure your Visual installation is complete (see sections just above).\n\n\nIf Qt does not autodetect the windows debugger, you might need to manually install the debugging tools for Windows, as stated on  [http://doc.qt.io/qtcreator/creator-debugger-engines.html this Qt Page].\nYou can get the Windows Driver Kit that contains the debugging tools from [https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit this page].\n\n\n\n\nSet up environment variables\n\n\n\ncreate a BCOMDEVROOT directory on your local hard drive\nFor instance at the following location:\n\n\n\n\n\n\n\n\n\n[path]/BCOMDEVROOT/windows\n\n\nAdd the following environment variable:\n\n\n\nBCOMDEVROOT= \"[path]/BCOMDEVROOT/windows\"\n\n\n\n\n\n\n\n\n\nDo not use \"\\\" in BCOMDEVROOT variable!!!\n\n\n\n\n\n\n\ncreate a XPCF_REGISTRY_PATH\n\n\n\n\n\n\n\n\n\n\nDo not use \"\\\" in BCOMDEVROOT variable!!!\n. that an XPCF_REGISTRY_PATH environment variable must be set, pointing to\nthe packages XML file\n\n\n\n\n\n\n\nthe XML file itself must be modified, depending on your installation: precisely\nyou will have to set the path to your package library\n\n\n\n\n\n\n\n\nInstall and build SolAR Framework\n\n\n\n\n\n\n\n\nit will install also SolarContainerOpenCV, a container of components SolAR compatible .\n\n\n\n\n\nDownload and build SolAR from scratch\n\n\n\nCreate a SolAR directory\n\n\nUsing a git client, clone the following repository on the develop branch:\n\n\ngit clone -b develop ssh://gitolite@forge.b-com.com/argo/tools/build-scripts.git\n\n\n\n\n\n\nwindows users\n\n\n\nDouble click on build-scripts/solarshell.bat\n\n\n\n\n\n\n\n\n\n\n\nExecute the following command:\n\n\n./build-scripts/fromscratch.sh\n\n\n\n\n\n\n\n\n\n\n\nCheck your SolARFramework has been correctly installed, in looking in your BCOMDEVROOT folder.\n\n\n\n\nOpen your BCOMDEVROOT{yourOS}\\bcomBuild\n\n\n\n\nYou should see a SolARFramework, a XPCF (pipeline manager) and a ContainerOpenCV directory.\n\n\n\ncheck your installation\n\nCheck the SolAR third parties have been correctly installed, in looking in your BCOMDEVROOT folder.\n\n\n\n\n\n\n\nOpen your BCOMDEVROOT{yourOS}\\thirdParties\n\n\n\n\nYou should see a boost and a opencv directory.\n\n\n\n\n\n\n\nlinux users\n\n\n\nOpen a terminal console, and go to your SolAR directory\n\n\nExecute the following command:\n\n\n./build-scripts/fromscratch.sh\n\n\n\n\n\n\n\n\n\nTest your first SolAR program\n\n\nOnce you have installed SolAR, you are able to run your first SolAR program.\n\n\nLook at your SolARframework folder\n\n\n\n\nYou can see you have installed:\n\n\n\n\nthe Core framework ins SolARFramework directory\n\n\na Container or Package based on OpenCV  .\n\n\n\n\nThe OpenCV container is a first implementation based on SolAR API.\nin this directory, you will see some features and tests.\n\n\n\n\n\n\n\n\n\n\n\ntous les tests devraient fonctionner, ce n&#8217;est pas le cas actuellement\n\n\n\n\n\n\nchoose a test program\n\nYou can for example open  the SolARDescriptorMatcher program.\nFor this program, and for each test, you can choose a dynamic or a static version.\nLet&#8217;s see with the static version here.\n\n\n\n\nOpen the SolARContainerOpenCV\\tests\\SolARDescriptorMatcher\\static folder.\n\n\n\n\nThere are source files, and a packagedepencies.txt files, precizing which third parties are used.\n\n\nNOTE : ce serait bien de préciser comment c&#8217;est utilisé techniquement\n\n\n\n\n\nJust have a look at packagedepencies.txt, it contains the definition of third parties used by this program.\n\n\n\n\n\n\nSolARFramework|1.0.0|SolARFramework|bcomBuild|url_repo_artifactory\n\n\nSolARContainerOpenCV|1.0.0|SolARContainerOpenCV|bcomBuild|url_repo_artifactory\n\n\nxpcf|1.0.0|xpcf|bcomBuild|http://repository.b-com.com/\n\n\nboost|1.64.0|boost|thirdParties|http://repository.b-com.com/\n\n\nopencv|3.2.0|opencv|thirdParties|http://repository.b-com.com/\n\n\n\n\n\n\nJust remind that the third parties shoule be available in your BCOMDEVROOT{yourOS}\\thirdParties repository.\n\n\nOpen it the pro file in your favorite IDE.\n\n\n\n\n\n\nconfigure your build\n\nConfigure the project build, add the \"make install\" line as described in this image.\n\n\n\n\n\nAdd also an image in arguments, so that the program can track the image in the camera vision.\n\n\n\n\n\n\nrun it\n\nThen build and tun the program.\n\n\n\n\n\n\n\n\n\n\n\nif you have problems for compiling or execute a program, feel free to contact us.\n\n\n\n\n\n\n\n\nUpdate and re-build SolAR\n\n\nWindows users\n\nDouble click on build-scripts/solarshell.bat\n\n\n\nUnix users\n\nOpen a terminal console, and go to your SolAR directory\n\n\nUpdate code source.\n\n\nFrom your SolAR folder, update the develop branches of the three following git repositories: SolarFramework, SolarContainerOpenCV and xpcf.\nTo do so, repeat the following commands inside the three folders, SolarFramework, SolarContainerOpenCV and xpcf:\n\n\n\n$ git checkout develop\n$ git pull origin develop\n$ git submodule update --init --recursive\n$ git submodule foreach git checkout develop\n$ git submodule foreach git pull origin develop\n\n\n\nRe-build SolAR\n\n\nRun:\n\n\n\n./build-scripts/build.sh debug\n\n\n\nand/or\n\n\n\n./build-scripts/build.sh release\n\n\n\n\n",
      id: 28
    });
    

  

    index.add({
      title: "create a component",
      content: "Create a component\n\nTable of Contents\n\nsubmenuconfig\ninstall cookiecutter\nget the templates\ncomponent\npackage\nfinalizing installation\nHow to create your Unit Test\nCreate your API documentation\nDOC API for Estimation pose developper\nComments for SolAR comunity\nGenerate API documentation with doxygen A REVOIR\nPublish your doxgen documentation A REVOIR\nCheck your documentation is available\nShare your component to the SolAR community\nComponent manager overview\nContact\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\ninstall cookiecutter\n\n\nThe easiest way to create a new component is to use our templates. SolAR templates\nare based on cookiecutter python package (see http://cookiecutter.readthedocs.io).\n\n\nTo install cookiecutter, simply run:\n\n\n\npip install cookiecutter\n\n\n\nWindows users: pip is located under the scripts folder of your python3 directory. Usually C:\\python3\\scripts.\n\n\n\n\nget the templates\n\n\nRun the following command to get SolAR templates:\n\n\n\ngit clone ssh://gitolite@forge.b-com.com/argo/tools/templates.git\ncd templates\n\n\n\n\n\ncomponent\n\n\nIn order to create a new component, all you have to do is run this command, and follow\nthe instructions:\n\n\n\n$ python template_component/cookiecutter_runner.py\n\n\n\n\n\npackage\n\n\nIn SolAR, components are wrapped into a library that we call a package. You can add you component\ninto an existing package project, or create a brand new package projet. Creating a package is easy\nbased on SolAR templates. Run this command, and follow the instructions:\n\n\n\n$ python template_package/cookiecutter_runner.py\n\n\n\n\n\nfinalizing installation\n\n\nIn order to use your component / package, do not forget:\n\n\n\n\nthat a BCOMDEVROOT (without backslashes on windows) environment variable\nmust be set, pointing to your installation folder\n\n\nthat an XPCF_REGISTRY_PATH environment variable must be set, pointing to\nthe packages XML file\n\n\nthe XML file itself must be modified, depending on your installation: precisely\nyou will have to set the path to your package library\n\n\n\n\n\n\nHow to create your Unit Test\n\n\nWrite your unit test\n\nDefine unit tests, based on boost framework .\nYou can know more about boost with this link : http://www.boost.org\n\n\nYour Unit tests for a specific component, should be placed in the component directory/unittest.\nIf you have used the SolARComponent template, this directory should be already there.\n\n\n\n\n\n\n\n\n\nOpen {yourcomponent}/unittest/{yourcomponent}unittest.pro\n\n\nYou have to describe your unit tests in the file  {yourcomponent}unittest.cpp\n\n\n\n\nFor example\n\n\n\n#define\nBOOST_TEST_MODULE \\{Yourcomponent}UnitTest\n\n#include &lt;boost/test/unit_test.hpp&gt; (1)\n#BOOST_AUTO_TEST_CASE(TestLoadImage) (2)\n{ // test execution instructions\n}\n\n\n\n\n\n1\nPlease note your code contains include of boost\n\n\n2\nYou have to define the name of your test thanks to the boost macro \"BOOST_AUTO_TEST_CASE\".\n\n\n\n\nIn this example , the definition of the test case \"TestLoadImage\" for your component.\n\n\nIt means, that when you will execute the unit test, it will executes this test \"TestLoadImage\" following the instructions in this declaration.\nYou can define several test cases.\n\n\nInside your test, please write a kind of demo main function, but where you check results of your component function thanks to macro BOOST CHECK and/or BOOST_TEST.\n\n\nYou will find easily information about BOOST macro on Internet http://www.boost.org/doc/libs/1_64_0/libs/test/doc/html/index.html [boost.org information,role=\"external\", window=\"_blank\"] .\n\n\n\n\n\n\n\n\nThere is no \"main\" function, as it is automatically generated by boost (used in unit tests).\n\n\n\n\n\n\n\nPlease ensure that it contains sufficient tests cases to verify your code is OK (normal case, error cases).\n\n\n\n\nExample here : // Case normal, with an existing image file.\n\n\n\n\n\n\n\n\nremplacer ici par le nouveau code source SolAR\n\n\n\n\n\n\nBOOST_AUTO_TEST_CASE(TestLoadImage)\n{ // To simplify this example test, let's suppose we'll test 'float'.\n // Some test are stupid, but all should pass.\n int result= 0;\n std::shared_ptr&lt;IArgoImage&gt; myArgoImage0 = getArgoImageInstance();\n\n....\nBOOST_CHECK( myArgoImage0 !=  NULL);\n....\n\n// getArgoImageInstance should not return a null pointer result\n\nmyArgoImage0-&gt;LoadImage(&quot;../test.jpg&quot;);\nBOOST_TEST( result= = 0,&quot;ARGO ERROR: Load Image should return 0&quot;);\n// As the image indicated exists, loadImage should return 0, as a normal case\n\n}\n\nBOOST_AUTO_TEST_CASE(TestLoadImageInexistante)\n{\n// Some test are stupid, but all should pass.\nint result= 0; std::shared_ptr&lt;IArgoImage&gt;\nmyArgoImage0 =  getArgoImageInstance();\n\n....\nBOOST_TEST(( myArgoImage0 !=  NULL),&amp;quot;ARGO ERROR: ArgoImage should not return null pointer&amp;quot;);\n\nresult=  myArgoImage0-&amp;gt;LoadImage(&amp;quot;../test2.jpg&amp;quot;);\nBOOST_TEST( result= = -1,&amp;quot;ARGO ERROR: Load Image should return -1&amp;quot;);\n....\n\n// As the image indicated does not exist, loadImage should return -1, an error\n\n }\n\n\n\n\nCheck your project unit tests\n\nRun it with the command line here\n*&gt;results.xml -x --log_format= XML -l all -o XML -m XML -r detailed\n\n\n\n\n\n\n\nExecute your unit tests. A command prompt should display results.\n\n\n\n\nEach test results is identified with its name\n\n\n\n\n\n\n\n\n\nThanks to the \"&gt;results.xml\" argument, a file should be created with  the resulta of your tests.\nThis are the results than jenkingswill use when your unit tests will be integrated in jenkins .\n\n\n\nAdd your unit tests in jenkins stream\n\nAdding unit tests in jenkins stream requires to modify a shell script in the ArgoAll git repository. First, clone ArgoAll and switch to the develop branch:\n\n\n\n\n\ngit clone -b develop ssh://gitolite@forge.b-com.com/argo/F-Argo/ArgoAll.git\n\n\n\n\n\nThen edit the file \"newbuild.sh\" inside the ArgoAll folder. Find the string \"# BUILDING AND RUNNING UNIT TEST\".\nYou will see several lines looking like this:\n\n\n\n\n\nmakeAndInstall &amp;quot;ArgoImageOpencv/unittest&amp;quot; &amp;quot;../../../../ArgoImageOpencv/unittest/ArgoImageOpencvUnitTest.pro&amp;quot;\n\n\n\n\n\n\n\nNow copy paste this line, and replace \"ArgoImageOpencv/unittest\" with \"[Yourcomponent]/unittest\" and \"ArgoImageOpencvUnitTest.pro\" by [YouComponentUnitTest.pro].\n\n\nThis new line will ensure that your test will be built by Jenkins.\n\n\nThen find the string \"running unit tests\". You will see lines looking like this: ./ArgoImageOpencvUnitTest --log_format= JUNIT --log_level= all --report_level= no --log_sink= ../../../tests/ArgoImageOpencvUnitTest.xml\n\n\nCopy paste this line, and replace : . \"ArgoImageOpencvUnitTest\" with [YouComponentUnitTest] . \"ArgoImageOpencvUnitTest.xml\" with[YouComponentUnitTest].xml\n\n\nThis new line will ensure that Jenkins will run your test. Save and close \"newbuild.sh\".\n\n\nCommit and push your changes. Done!\n\n\n\n\n\n\n\nCreate your API documentation\n\n\n:toclevels:2\n\n\n\n\n\n\n\n\nNOT VALIDATED\nTIP: Write here if you validate with your name and your comment\n\n\n\n\n\nSee doxgen syntax, with the samples given by SolAR framework.\n\n\n\n\n\n\n\n\nIf you use QT creator, you can use the DOXYGEN comments completions (check if activated in options/completion)\n\n\n\n\n\n\n\nDOC API for Estimation pose developper\n\n\nIf your documentation is destinated to Estimation Pose Developper or designer, aka framework users, you just need to comment your H files that are shared in SolAR framewok\n\n\n\n\n\n\n\n\nremplacer ici par le GIT SolAR\n\n\n\n\n\n\n\n\ngit clone ssh://gitolite@forge.b-com.com/argo/F-Argo/ArgoFramework.git\n\n\n\n\n\nThis is a subpart of documentation, as Framework users don&#8217;t need to know how the SolAR framework is built inside.\n\n\n\n\nComments for SolAR comunity\n\n\n\n\n\n\n\n\nje pense que cette partie n&#8217;est pas claire, à reformuler\nYou have to comment your whole code with the same format as the H files, with doxygen format.\nNo Doxygen documentation will be generated, but the comments will help the SolAR comunity to understand and contribute to the code.\n\n\n\n\n\n\n\nGenerate API documentation with doxygen A REVOIR\n\n\n\n\n\n\n\n\ncette partie est à revoir complètement, suite à l&#8217;intégration de la création de doc DOXYGEN dans jenkins.\nDownload Doxygen http://www.stack.nl/~dimitri/doxygen/\nInstall it on your computer.\nYou can use Doxygen in two modes. Run Doxygen :\n\n\n\n\n\nYou just have to run Doxygen on the \"SolARFramework\" project.\nIt will generate API documentation based on H files in the SolAR framework repository. *The API documentation will be available in a directory named doxygen and subdirectory html.\n\n\n\n\nPublish your doxgen documentation A REVOIR\n\n\n\n\n\n\n\n\ncette partie est à revoir complètement, suite à l&#8217;intégration de la création de doc DOXYGEN dans jenkins.\ncopy and paste your doxygen directory from the working directory with your clone of SolAR website.\nIf not already done, execute:\n\n\n\n\n\n\n\n\n\n\n\nremplacer ici par le GIT SolAR\n\n\n\n\n\n\n\n\ncd c:/DEV/websiteSolAR\ngit clone ssh://gitolite@forge.b-com.com/argo/Argo-Doc/argo-site.git solAR\ngit checkout develop\n\n\n\n\n\nadd your doxygen directory in git website directory example\n\n\n\n\n\n\n\n\nremplacer ici par le GIT SolAR\n\n\n\n\n\n\n\n\ncp doxygen c:/DEV/solAR\ncd c:/DEV/solAR\ngit status\ngit commit\ngit checkout\ngit push\n\n\n\n\n\n\n\nCheck your documentation is available\n\n\nConsult this link to be sure the documentation is up-to-date.\n\n\n\n\n\n\n\n\nchanger le lien avec le nouveau lien\n\n\n\n\n\n\n\n\n\n\n\nremplacer ici par le lien doc SolAR\n\n\n\n\n\nhttps://forge.b-com.com/www/SolAR/doxygen/html/\n\n\n\n\nShare your component to the SolAR community\n\n\n\n\n\n\n\n\nNOT VALIDATED\nTIP: Write here if you validate with your name and your comment\n\n\n\n\n\nCommit your component to the gforge\n\nIn your new SolARComponent folder\n\n\n\n\n\ngit init\n\n\n\n\n\nAdd an initial file for the first commit\n\n\n\n\n\ngit add README.adoc\n\n\n\n\n\nFirst local commit\n\n\n\n\n\ngit commit -m \"first commit : README.adoc\"\n\n\n\n\n\n\n\n\n\n\n\nest-ce encore d&#8217;actualité? on n&#8217;aura plus un GIT par composant,si ?\nCreate the git repository on the gforge.\nFor example, here the url of the ArgoDescriptor component\n\n\n\n\n\nPush the first file to the distant repository\n\n\n\n\n\n\n\n\nremplacer ici par le GIT SolAR\n\n\n\n\n\n\n\n\ngit remote add origin http://forge.b-com.com/git/argo/F-Argo/packages/ArgoDescriptor.git\ngit push --set-upstream origin master\n\n\n\n\n\nMove to the develop branch git branch develop\n\n\n\n\n\ngit push --set-upstream origin develop\n\n\n\n\n\n\n\n\nComponent manager overview\n\n\nThe component manager will help you to load and use your component.\n\n\nPlease have a look at the component manager to know how to create your component compliant with the framework.\n\n\nPlease click here to know more about  XPCF, the component manager used in SolAR framework.\n\n\n\n\n\n\n\n\nrajouter lien ici\n\n\n\n\n\n\n\nContact\n\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 29
    });
    

  

    index.add({
      title: "contribute to core",
      content: "Contribute to Core\n\nTable of Contents\n\nsubmenuconfig\nSolAR Core presentation\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nSolAR Core presentation\n\n\nThe SolAR core handles\n\n\n\n\nthe dynamic load of different components embedded in containers downloaded from different distant servers.\n\n\nthe connection between some of these components, their configuration\n\n\nthe feature of saving the  pose estimator scheme (the required components, their configurations as well as their connectivities)\n\n\nto build a dynamic library that could be directly used by third applications.\n\n\n\n\nA well-detailed documentation of the SolAR core will coming soon.\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 30
    });
    

  

    index.add({
      title: "best practices",
      content: "Best practices\n\nTable of Contents\n\nsubmenuconfig\nBest practices\nLogs to help debugging\ncoding rules\nProject organization\n\nFiles\n\n\nC / C++ Coding Rules\n\nLanguage features\nLibraries and headers\nNaming conventions\nDesign conventions\nLayout conventions\nTracing and debugging\nError handling\nMiscellaneous conventions\nDocumentation\nC/C++ Performance rules\nTools\n\n\nAppendix A.\tCode sample\n\nI.\tPrototype C++ header file\nII.\t Prototype C++ source file\nIII.\tHow to remove ‘goto’\n\n\nAppendix B.\tRules management\n\nI.\tResponsibility\nII.\tDeviation\nIII.\tTraining\nIV.\tControl\n\n\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nBest practices\n\n\nSolAR is a framework that defines interfaces (API) to computer vision components and a GUI that is used to graphically build Camera Pose Estimation schemes, based on the framework, for different applications/needs.\nThe following rules shall be used for every addition/modification to the SolAR project.\nThis encompasses the SolAR framework and the GUI interface and unless otherwise specified, these rules shall apply to both.\n\n\n\n\nLogs to help debugging\n\n\nA SolARLog tool has been defined in order to help you to debug and test your programs.\n\n\nSolarLog is based on spdlog, and is managed as a singleton, so that you will have at maximum 2 loggers : 1 console and 1 file.\n\n\nYou have  2 log modes\n\n\n\n\nconsole\n\n\nfile\n\n\n\n\nPlease initiate your console logger with  LOG_ADD_LOG_TO_CONSOLE or file logger thanks to  LOG_ADD_LOG_TO_FILE.\n\n\nYou will easily find examples in SolAR sample codes.\n\n\nPlease use one of this macro to log your data, depending on the severity you want :\n\n\n\n\nLOG_TRACE: create a TRACE of INFO level\n\n\nLOG_INFO(fmt, &#8230;&#8203;) : create a log of INFO level\n\n\nLOG_DEBUG(fmt, &#8230;&#8203;) : create a log of DEBUG level\n\n\nLOG_CRITICAL(fmt, &#8230;&#8203;) : create a log of CRITICIAL level\n\n\nLOG_WARNING(fmt, &#8230;&#8203;) : create a log of WARNING level\n\n\nLOG_ERROR(fmt, &#8230;&#8203;)  : create a log of ERROR level\n\n\nLOG_FLUSH : can be used to force logs flush (console or file mode)\n\n\nLOG_RELEASE : is used to release the logger (should be used at the end of a program).\n\n\n\n\n\n\ncoding rules\n\n\n\n\n\nProject organization\n\n\nIn order to ease the source code management, we should follow the same hierarchy for each module. A module typically becomes one dynamic or static library (dll or lib). To make the code more accessible and friendly for everyone, developers should follow the rules below:\n\n\nFiles\n\n\n\n\n\n\n\nC++/C modules\n- Project-wide definitions must be in a dedicated header file (for instance definitions.h)\n- Each module may have a common .h file that contains all common constants, macros, enum, structures… It should not contain elements that are not common to classes in the module.\n\n\nC++/C source files\nC++/C source files should contain the implementation of only one class (except for very small private utility classes related to that class).\nSee Naming conventions for naming conventions.\n\n\nC++/C headers files\nC++/C headers files should contain the declaration of only one class (except for very small public utility classes related to that class).\nSee Naming conventions for naming conventions.\n\n\nDirectory layout for each module\nThe directory layout for each module should be as described in:\n coding_rules.adoc chapter Project organisation\n\n\n\n\n\n\n\nC / C++ Coding Rules\n\n\n\n\n\n\n\n\nNOT VALIDATED\nTIP: Write here if you validate with your name and your comment\n\n\n\n\n\nWhy restricting C++?\n\n\nEven if compilers now correctly compile even the most advanced C++ language features, some advanced features make the code overly complex and difficult to maintain.\n\n\nWhy restricting C?\n\n\nC can be written in many ways to do the same things but some ways are more obfuscated and offers less robustness.\n\n\nThen, what language to use?\nb&lt;&gt;com is using a mix of C and C++ based on existing code, external dependencies (like platform types, SDK, etc).\n\n\nThat’s why the following rules makes sense in our environment and, in order to facilitate porting and code review, developers must use the set of rules defined below. An example of code and header can be found in annexes A1 and A2.\n\n\nLanguage features\n\nAs it is very easy to make unreadable and non-understandable C code, here are a few rules/restrictions to follow for the C language itself:\n\n\n\n\n\n\n\n\nTemplates\nTemplates should be used following the \"KISS\" principle. Extreme template programming must be avoided and replaced with ad-hoc design to ensure code maintainability.\n\n\nExceptions\nExceptions must not be used outside package boundary (i.e. outside a static or dynamic library no exception must be thrown).\n\n\nOperator overload\nOperator overloading should be used appropriately.\n\n\nWeird language features of C++\nWeird language features of C++ must not be used, especially:\n- static variables that invoke constructors at initialization time  (except for some very special cases, such as the singleton pattern)\n- run-time type information (‘casts’ can fail at run-time)\n\n\nBit fields\nBit fields must not be used for the following reasons: they are not portable because the implementation of bit fields is left to the compiler manufacturer according to the platform; and usage of bit fields is usually inefficient in terms of code size. Use one variable instead of each bit field.\nConsider using the STL bitset template class instead.\n\n\nNamespaces\nNamespaces may be used for std classes to avoid the full Class::methName statement. But for internal classes with ambiguous names, try to always use their full class name.\n\n\n'goto' keyword\nThe 'goto' keyword should not be used, and if it is, it can only be used to jump to the end of a method for error recovery.\nBy considering the architecture of a method, this keyword can nearly always be avoided.\nSee annex A3 for examples.\n\n\n‘continue’ and ‘break’ keywords\nThe ‘continue’ statement should not be used; the ‘break’ statement should not be used except inside switch statements.\n\n\n‘return’\nThe 'return' keyword may be used anywhere in the code.\nHowever, it requires that the no dynamic allocation rule is respected (see below) and that no vital code is skipped.\nIt also requires that all synchronization is made through C++11 lock_guard objects.\n\n\nC++ types\nTypes such as bool, etc. may be used if they are not platform dependant.\n\n\nC++ iostreams\nIostreams should be used.\n\n\nDynamic memory allocations\nDynamic memory allocation should be avoided.\nMost of the time, C++ offers semantics that allows no dynamic allocation design.\nmalloc/free, new/delete should be used during initialization sequence (in the class constructors for instance)\nDuring run time, explicit memory allocations should not be used to avoid memory fragmentation and leaks.\nIf an array is needed at some point during the execution of the program, this need should preferably be planned and reserved at the initialization sequence.\nLocal arrays are recommended if they are small in size (no more than 16-32 values).\n\n\nArrays\nuse STL&#8217;s vector&lt;T&gt; and array&lt;T&gt; instead of old C-style arrays, as C-style arrays don&#8217;t behave as expected with C++ objects.\n\n\nDynamically allocation of member (aggregated/composed) object\ndynamic allocation of a \"local\" object must occur only when the inner object lifetime is different from the \"hosting\" class (aggregation case) OR when the used framework doesn&#8217;t allow the creation of the object upon class creation (for instance, when no default constructor is available).\nWhen dynamically allocating inner objects, prefer the use of STL&#8217;s shared_ptr or unique_ptr (depending on the inner object lifetime), to ensure proper behavior upon exception throwing &#8230;&#8203;\n\n\nClass instantiations during run time\nAll the necessary classes, arrays, structures should be present, allocated and initialized before run time (during the initialization sequence) except for transient objects (objects operated by a pipeline should be created at the beginning and destroyed at the end for instance)\n\n\nConstants\nConstants must be declared using static const or enum for enumeration of constants. #define must be avoided (language evolution tends to avoid #statements).\n\n\nconst\nconst keyword MUST be used. It must be used appropriately.\nUsed on method parameters, it clearly shows when a parameter is an input, input/output or output parameter.\nUsed for methods, it clearly shows that const methods leave the underlying object members unmodified. (typically getters should be const methods).\n\n\n\n\nC++11\n\n\n\n\n\n\n\n\nMove semantics\nMove semantics must not be used. In most cases, move semantics can be replaced with designing the method using C++ references upon output parameters, or with the use of STL shared_ptr.\n\n\nLambdas expressions\n\n\n\nThreads\nC++11 threads and related facilities (mutex, scoped lock_guard, future &#8230;&#8203;) must be used\n\n\nLiterals\n\n\n\nRange for\nRange for must be used to work on containers as it improves the code readibility\n\n\nauto\nauto keyword use is recommended when it simplifies the code readibility.\nIt allows to avoid explicit typing of objects when there&#8217;s not a strong interest to :\n- for iterators\n- for temporary objects\n\n\nsmart pointers\nSTL&#8217;s smart pointers must be used. When possible, it should replace most of old C-style pointers (DLL boundary issue ?)\n\n\nFunction objects\nstd::function, std::bind, std::mem_fn &#8230;&#8203; readibility, maintainability issues ?\n\n\nSTL containers initializer list\n\n\n\nDate and time\nSTL chrono, useful also for performance counters\n\n\nSTL\narray&lt;T&gt;, bitset&lt;T&gt;\n\n\n\n\n\nLibraries and headers\n\n\n\n\n\n\n\nSTL containers\nSTL should be used for container types, such as vectors, lists, maps, etc. (but must not be used across DLL boundaries).\n\n\nC++ strings\nThe C++ string object should be used for string manipulation (but must not be used across DLL boundaries).\n\n\nC++ 'cin', 'cout', 'cerr'\nThe C++ 'cin', 'cout', 'cerr' must not be used (except inside unit test code and command line tools).\n\n\nC 'stdin', 'stdout', 'stderr'\nThe C 'stdin', 'stdout', 'stderr' must not be used (except inside unit test code and command line tools).\n\n\nC headers/libraries\nC headers/libraries may be used.\n\n\nSystem specific headers/libraries\nSystem specific headers/libraries must not be used\n(except in system specific source code – in that case it should be clearly isolated and identified). The code should use as little as possible the windows SDKs (tradeoff between using existing code and code created from scratch).\n\n\nMultiple header include\nTo avoid multiple definitions, each header must have:\n#ifndef HEADERNAME_H\n#define HEADERNAME_H\n&lt;header&gt;\n#endif // HEADERNAME_H\n\n\nInclude inside header files\n#include should not be inside header files in order to avoid include files obfuscation, and to prevent some cases of bad build of a project which shares dependencies with a non-rebuilt project.\n\n\nFunction and variable declaration\nFunction and variable declarations must be done in header files (and not in other files).\n\n\n#pragma once\nUse of #pragma once is prohibited :\n- even if it is supported by a vast majority of c++ compilers, it is not a standard directive of the language\n- although it protects from header naming conflict, it doesn&#8217;t prevent from ncluding a header twice if it exists in more than one location in a project as files are excluded based on their filesystem-level identity.\n\n\n\n\n\nNaming conventions\n\n\n\n\n\n\n\nNOT VALIDATED\nTIP: Write here if you validate with your name and your comment\n\n\n\n\n\n\n\n\n\n\n\nAbout names\n- Words must be in English.\n- Words inside the name must start with an uppercase letter. Other letters of the word must be lowercase letters (except for constants).\n- Names should not contain underscores '_' (except for constants and the prefixes as specified bellow).\n- Names should not contain abbreviations (except if the abbreviation is widely used in the particular field, such as ESDescriptor for “elementary stream descriptor”).\n- Names should be explicit according to what they will do, avoid generic names (like i, a, x…).\n\n\nC++ source files\nC++ source files must begin with the name of the class followed by ‘.cpp’.\n\n\nC source files\nC source files must begin with the name of the class followed by ‘.c’.\n\n\nC++/C headers files\nC++/C header files must begin with the name of the class followed by ‘.h’.\n\n\nC++ template headers files\nC++ template header files must begin with the name of the class followed by ‘.[inl|tpl]’.\n\n\nC++ template source files\nC++ template source files must begin with the name of the class followed by ‘.[ipp|tcc]’.\n\n\nClasses,\nstructures,\nglobal functions, structure tags, typedefs,\nenumerated values\nClass names, structure names, global functions, structure tags, typedefs, enumerated values must have their name beginning with an uppercase.\nExample MatrixBase\n\n\nMethods\nMethod names must begin with a lowercase letter (except for constructors and destructors).\nExample\treadAccessUnit()\n\n\nPrivate members\nPrivate member variable names must be prefixed with 'm_' and start with a lowercase letter.\nExample\tm_accessUnitList\n\n\nPrivate static members\nIf used, private static member variable names must be prefixed with 's_' and start with a lowercase.\nExample\ts_socketCounter\n\n\nLocal variables\nLocal variable names must start with a lowercase letter.\nExample\tdataLength\n\n\nConstants\nConstants must be all uppercase with each word separated by “_”.\nExample\tMAX_LENGTH\n\n\n\n\n\nDesign conventions\n\n\n\n\n\n\n\nMultiple inheritance\nPolymorphism\nMultiple inheritances should not be used, except if the additional classes are pure virtual (equivalent to Java interfaces).\n\n\nClasses with public virtual methods\nClasses with public virtual methods must have a virtual destructor (or else the destructor will not be called). When possible, use the appropriate compiler warning to be warn when destructor isn&#8217;t declared virtual while some public methods are.\n\n\nStatic member variables\nStatic member variables must not be used (these are basically “global variables”). (except for singleton design pattern)\n\n\nPublic member variables\nPublic member variables must not be used (except in pure “struct-like” classes). Instead, getter and/or setter methods should be provided to access member variables.\nExample\tint getMember()\n{\n&#8230;&#8203;.return m_member;\n}\nError setMember(int variable)\n{\n&#8230;&#8203;.if (variable&#8230;&#8203;)\n&#8230;&#8203;.{\n&#8230;&#8203;&#8230;&#8203;..m_variable = variable;\n&#8230;&#8203;&#8230;&#8203;..return NoErr;\n&#8230;&#8203;.}\n&#8230;&#8203;.return Error_NUMBER;\n}\n\n\nUnsigned/signed types\nSigned and unsigned computations should not be mixed. Signed and unsigned doesn’t work well together and are, in many cases, not comparable one another.\nSituations like “comparing unsigned values with potentially negative values” or “use signed computations to be casted into unsigned variables” makes the code vulnerable.\n\n\nSigned types\nUnsigned types  should be used.\nSigned types should only be used when the value for the variable or parameter in question could sensibly be negative.\n\n\n'enum' type\nFor variables or parameters that may take one of a set of values whose representation is arbitrary, the enum type should be used.\nExample\tenum CM_Colors { CM_RED, CM_GREEN, CM_BLUE };\n\n\nDynamic length structure\nIt is recommended to avoid structures with dynamic length. However, if they are used, the size should be bounded in size in order to avoid unlimited memory occupation.\n\n\nPreprocessor definitions\nThe definition and use of preprocessing flags (#ifdef/#ifndef) in the source code should be limited; in particular, there should not be any OS or compiler specific code.\nHowever, if specific code is present, it should be isolated and clearly identified.\nMost of the time, a different design approach allows to avoid inlined OS preprocessor definitions (namespace or inheritance usage for instance).\n\n\nCode under conditional compilation flags\nCode under #if, #ifdef, #ifndef should be limited. Theses sections, if not build with the rest of the code, can easily be broken without notice.\n\n\nInline\nInline may be used instead of macro for functions that are called often and when they are more than one line long.\n\n\nRange of variables\nConsider the range of each variable: each variable should remain local to a code block as much as possible.\nVariable like the for iterator can remain local to the loop. If the if condition statement block needs a local variable: declare it inside the statement block. This variable will not be visible outside the block, preventing misuse.\nNote for Intel compilers: before ICC11, declaring a variable into a for statement for (int myVariable;…) resulted in having the variable defined locally to the function containing the for. With ICC11, this variable exists only with the for statement code block.\nExample\tif (myCondFct())\n{\n&#8230;&#8203;.\tint myLocalVar = methodVar * m_aMember;\n&#8230;&#8203;.useMyLocalVar(myLocalVar);\n}\naMethodThatCanNotUseMyLocalVarHere();\nmyLocalVar is only used in the if statement block. If someone attempts to use it outside, the project will not build. This variable only serves that code block and it is not useful outside. The code is easier to read, no need to monitor myLocalVar, or wonder if it is used elsewhere…\n\n\nScope of variables\nAvoid using one variable for multiple purposes (the compiler handles this optimization process better than anybody).\n\n\nCode organization\nIt is recommended to differentiate:\n- Functions dedicated to computing.\n- Functions dedicated to schedule and control the computing functions.\n- Functions dedicated to data flow management.\nExample\tError computeFunc(UInt32* res, UInt32* sourceTable)\n{\n&#8230;&#8203;.// compute code\n&#8230;&#8203;.res = sourceTable[0] * sourceTable[1] + MY_CONST;\n&#8230;&#8203;.return NoErr;\n}\nError dataFlowFunc(MyStruct destStruct, MyStruct* sourceStruct)\n{\n&#8230;&#8203;.// copy struct\n&#8230;&#8203;.memcpy(destStruct, sourceStruct, sizeof(destStruct));\n&#8230;&#8203;.return NoErr;\n}\nError controlFunc(MyStruct* destStruct, MyStruct* sourceStruct, UInt32* sourceTable)\n{\n&#8230;&#8203;.Error err;\n&#8230;&#8203;.UInt32 res;\n&#8230;&#8203;.err = computeFunc(&amp;res, sourceTable);\n&#8230;&#8203;.if (err == NoErr)\n&#8230;&#8203;.{\n&#8230;&#8203;&#8230;&#8203;..err = dataFlowFunc(destStruct, sourceStruct);\n&#8230;&#8203;.}\n&#8230;&#8203;.return err;\n}\n\n\nThread concurrency\nUse threads with caution. It is recommended to ask architecture experts about the use of threads. Use C++11 threads' library.\n\n\nSingleton design pattern\nThis pattern should not be used unless absolutely needed. When used, special care should be taken to consider concurrent access issues; the unique instance should be automatically created in the first call of “getInstance”; and the constructor should be declared as private.\nSometimes, a statically created singleton is the prefered choice (more than the dynamically created one).\n\n\nCasts\nCasts should not be used unless absolutely needed. C-style casts must be prohibited and replaced with C++ casts.\nExample\tUInt16 var1;\nUInt32 var2;\nUInt64 myResult;\nmyResult = var1 * var2;\nmyResult = (UInt64) var1 * var2;\nmyResult = UInt64(var1) * UInt64(var2);\n\n\n\n\n\n\n\n\n\n\nDon&#8217;t put two methods calls on the same line. Don&#8217;t put break keyword in switch/case statement at the end of a processing line.\n\n\n\n\n\n\nLayout conventions\n\n\n\n\n\n\n\nTabs\nTabs must not be used. Spaces must be used for indentation. Editors should be set to fill with spaces, not tabs. Tab settings tend to be different for editors, printers and web pages.\nNote: This is obviously an arbitrary choice, but mixing tabs and spaces causes much difficulty in reviewing code…\n\n\nIndentation\nIndentation offset must be set to 4 spaces and is performed according to the following rules:\n- code surrounded by braces must be indented by one level.\n\n\nBlank lines\nA blank line should be used to separate logically distinct sections of code.\n\n\nCurly brackets\nCompound statements (if, else, else if, while, for, switch, do) must ALWAYS make use of curly brackets, even where the \"associated\" body only consists of a single line. Structures must use curly brackets around the clause.\n\n\nCurly brackets\nCurly brackets should appear at the beginning of the next line or at the end of the line.\nExample\tif (a == b) {\n&#8230;&#8203;.c = 0;\n}\nelse {\n}\nif (a == b)\n{\n&#8230;&#8203;.c = 0;\n}\nelse\n{\n}\n\n\nParentheses\nAlthough C++ has precedence rules that should ensure a given expression is evaluated in the same order regardless of the compiler, additional parentheses should be used where the order of evaluation is not obvious.\n\n\nMultiple parentheses\nParentheses on multiple lines must be aligned on the previous parentheses with the same level. Operators must be at the end of the lines.\nExample\tif (a == b) &amp;&amp; &#8230;&#8203;..(c == d ||\n&#8230;&#8203;.(e == f))\nif (a == b) &amp;&amp; (c == d ||\n&#8230;&#8203;.(e == f))\n\n\nFunctions\nEach function should perform a single well-defined operation.\nFunctions should not be too long. Up to 2 pages of printout or about 100 lines of source code is reasonable. These figures include comments and blank lines.\n\n\nSource files\nSources files must be small. 1000 lines of source code is reasonable (including comments and blank lines).\nThese files are easier to read and faster to compile (Intel compiler can compile several source files in parallel).\n\n\nHeader files\nHeader files must be small. 100 lines for headers are reasonable.\n\n\nSwitch\nCase/default from a switch statement are written on the same column as the switch keyword. break; and other lines are indented.\n The break keyword must ALWAYS be on its own line. Mixing the break keyword with processing code makes the code confused : it can be interpreted as \"fall-off\" code when break is at the end of long lines.\nExample\tswitch (getStyle(config))\n{\ncase STYLE_GOOD:\n&#8230;&#8203;.// Ah, it&#8217;s so good!\n&#8230;&#8203;.break;\ncase STYLE_BAD:\n&#8230;&#8203;.// Oh no, it&#8217;s bad!\n&#8230;&#8203;.break;\ndefault:\n&#8230;&#8203;.// Hmmm!\n&#8230;&#8203;.break;\n}\n\n\nInstructions\nPut one instruction per line.\n\n\nfor\nAlways put curly brackets in for clause. for instructions must be on their own lines (not on the for line)\n\n\n\n\n\nTracing and debugging\n\n\n\n\n\n\n\nBoost::log\nBoost::log is the recommended framework to log, as it provides great functionality out of the box without the need for extra/complex configuration\n\n\n\n\n\nError handling\n\n\n\n\n\n\n\nDefault error codes and types\nThe default error codes and error types should be declared in a common b&lt;&gt;com header file.\n\n\nType of value returned for error codes\nThe type of value returned for error codes should be Error.\nExample\tError parseString(char *str);\n\n\nMemory allocation\nA method that attempts to allocate memory must provide an allocation failure mechanism, typically by returning an error code. Note that other methods that call such a method must also provide a failure mechanism, and so on&#8230;&#8203; Memory allocation should not be performed in constructors as constructors don’t return error code.\n\n\nFile management\nThe success of a file opening must be checked and if not successful, the error must be handled appropriately.\nFiles must be closed when no longer used or when an error to exit occurs.\nWhen closing the file, the return value must be checked.\n\n\nFunction call\nThe success of a function call must be checked and if not successful, the error must be handled appropriately. The error codes returned by functions must be tested and treated.\n\n\nInit/deinit functions\nAfter calling constructors and before destructors, it is sometimes necessary to call init and deinit functions to permit error handling on structures that might fail (as these errors cannot be handled in constructors and destructors.\n\n\n\n\n\nMiscellaneous conventions\n\n\n\n\n\n\n\nCompiler warnings\nSource code must not have any warnings when compiled on any targeted platform with any targeted compiler (with a reasonably high warning level – at least level 3).\n\n\nC – C++ interfacing\nAll C public interfaces (*.h) which may be compiled with a C++ compiler must wrap the contents of the file with the pair of macros BEGIN_EXTERN_C and END_EXTERN_C.\nExample\tBEGIN_EXTERN_C\nEND_EXTERN_C\n\n\nC++ interfacing\nAll C class headers (*.h) which may be compiled with a C compiler must include a C API and ensure the non visibility of C code by putting it within an “#ifdef __cplusplus … #endif” statement.\n\n\nDynamic library export\nThe definition of each class or function that is exported in a dynamic library must be preceded by the XX_EXTERN keyword, XX being the prefix for the module to which the class belongs.\n\n\nPortability\nSee http://www.mozilla.org/hacking/portable-cpp.html for more miscellaneous recommendations on portability on various platforms. If a rule differs from b&lt;&gt;com coding rules, follow the b&lt;&gt;com coding rule.\n\n\n\n\n\nDocumentation\n\n\n\n\n\n\n\nCopyright\nEach b&lt;&gt;com source and header file must use the template copyright header comment.\n(See Annex A1: .h)\nSource from other origins (Open Source for example) may have their own license. In this case, the license must be respected. The headers of third party files must be left intact (then it should not be replaced by b&lt;&gt;com copyright).\n\n\nPrimary documentation\nof a class\nThe primary documentation of a class must appear in the header file.\n\n\nClass description\nEach class must have a description before the class declaration.\n(see Annex A1: class description)\n\n\nMethods\nEach method (public, protected and private) must have a short description before the method declaration.\n(see Annex A1: setup method description)\nA method that is already sufficiently documented in the superclass may omit the description or have a single-line comment '// see superclass'\n(see Annex A1: clone method description)\n\n\nMember variable\nEach member variable must have a description either before the member variable declaration or on the same line.\n(see Annex A1: member description)\n\n\nComments\nComments are written in English. Do not use accented characters in source files.\nAll comments should be “DOxygen” compatible (see Tools). All tags must start with ‘@’ and not ‘\\’.\nEach block of code should be commented. Algorithms must be commented.\nBugs from Bugzilla must not be referenced in the code.\n\n\n/*…/\nThis type of comment block must be used for comments that apply either to a class, a function, a structure, an enum, a member… which is present below the comment block.\n(see Annex A1: class description)\n\n\n//\nThis comment line should be used inside the code to comment lines in C++ sources. They should be used even for block of comments.\n(see Annex A2)\n\n\n/…/\nThis comment block should not be used for C++ except for the template copyright block on top of the file and for method and variable documentation.\n\n\n\n\n\nC/C++ Performance rules\n\nBecause we need performance for all code types to achieve close-to-realtime target, these rules replace corresponding rules in previous chapters in order to ensure better software performance.\nFor C++, to improve performance, classes must act as evolved structures/handlers. They must point at a set of non reentrant methods (avoiding static code, allowing parallelism, allowing instantiation).\n\n\n\n\n\n\n\n\n'goto' keyword\nThe 'goto' keyword must not be used.\n\n\n‘continue’ and ‘break’ keywords\nThe ‘continue’ statement must not be used; the ‘break’ statement must not be used outside of switch statements.\n\n\nC++ &#8594; C convertibility\nC++ source must always be convertible into C code. If the rules associated with classes are followed, a class can be immediately converted into a structure and a bunch of methods with, as parameter, a handle on the structure that represents the former members.\n\n\nRecursive code\nRecursive code must not be used for performance reasons and lack of control over the code and because no parallelization and optimization are possible.\n\n\n?No class as class member?\nA class must not contain another class as a member except through pointers.\n\n\nStructures must not contain arrays\nA structure (class or struct) must not contain arrays except through pointers.\nThe size of the structures must remain reasonable.\n\n\nDynamic memory allocation\nDynamic memory allocation must not be used.\nmalloc/free, new/delete must be used during initialization sequence (into the class creators for instance)\nDuring run time, explicit memory allocation must not be used to avoid memory fragmentation and leaks.\nIf an array is needed at some point during the execution of the program, this need must be planned and reserved at the initialization sequence.\nLocal arrays are tolerated if they are small in size (no more than 16-32 values).\n\n\nClass instantiations during run time\nAll the necessary classes, arrays, structures must be present, allocated and initialized before run time (during the initialization sequence).\n\n\nDynamic length structure\nDynamic length structures must not be used (in order to avoid unlimited memory occupation).\n\n\n\n\n\nTools\n\n\n\n\n\n\n\nUncrustify\nMost of the code formatting rules described in this document can be enforced using “uncrustify”.\n\n\nDOxygen\nDOxygen extract comments from the source code and generates documentation. It is recommended to check the comment structure with this tool.\nRefer to the online manual (http://www.stack.nl/~dimitri/doxygen/index.html) for a complete description of DOxygen rules.\n\n\n\n\n\n\n\nAppendix A.\tCode sample\n\n\nI.\tPrototype C++ header file\n\n\n\n\n\n\n\nII.\t Prototype C++ source file\n\n\n\n\n\n\n\nIII.\tHow to remove ‘goto’\n\n\n\n\n\n\n\n\n\nAppendix B.\tRules management\n\n\nI.\tResponsibility\n\nThe Development group manager is responsible of these rules.\n\n\n\nII.\tDeviation\n\nAny b&lt;&gt;com source code must follow these rules. Third party package follow their own rules and should not be modified to follow these rules.\n\n\n\nIII.\tTraining\n\nAny C/C++ developers and integrators must be trained to these rules.\n\n\n\nIV.\tControl\n\nThe compliancy with these coding rules can be performed with Uncrustify tool with the appropriate config file (see tools).\n\n\n\n",
      id: 31
    });
    

  

    index.add({
      title: "contribution workflow",
      content: "Contribution workflow\n\nTable of Contents\n\nsubmenuconfig\nContribution workflow\nContribute to SolAR Framework\nContributing by creating your own components\nContact\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nContribution workflow\n\n\n\n\n\n\n\n\n\nContribute to SolAR Framework\n\n\nContributers may be interested in enhancing Solar Framework. For instance, they may want to:\n\n\n\n\ndefine new interfaces or new data structures\n\n\npropose bug fixes\n\n\netc.\n\n\n\n\nThe proposed workflow is based on github forks and pull requests:\n\n\n\n\nif not already done, create a github account: github\n\n\nopen to the following url: github SolARFramework\n\n\nclick on the \"fork\" button in order to copy SolARFramework to your own github account\n\n\nkeep your fork up to date: read the page help github in order\nto sync your local copy of SolarFramework with the original repository\n\n\n\n\nYou may then ask the upstream repository to accept your changes: this is performed by creating a pull request.\nFollow the instructions at pull request documentation to see how to create a pull request\nbetween your fork and the original repository.\n\n\nWhen your pull request is created, request for a pull request review, by following these instructions: https://help.github.com/articles/requesting-a-pull-request-review/\n\n\n\n\nContributing by creating your own components\n\n\nYou may be interested by developing your own components based on SolAR interfaces.\nIn this case, create your own github repository, and create any SolAR components and packages you need by following these instructions.\n\n\nOnce your component is created, don&#8217;t hesitate to contact us!\n\n\n\n\nContact\n\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 32
    });
    

  

    index.add({
      title: "tools",
      content: "Tools\n\nTable of Contents\n\nsubmenuconfig\nAccess to Forge\nAccess to Jenkins\n\n\n\nsubmenuconfig\n\n\n\n\nhow it works\n\n\ngetting started\n\n\ncreate a component\n\n\ncontribute to core\n\n\nbest practices\n\n\ncontribution workflow\n\n\ntools\n\n\n\n\n\n\nAccess to Forge\n\n\n\n\n\nAccess to Jenkins\n\n\ncoming soon\n\n\n",
      id: 33
    });
    

  

  
  
  

    index.add({
      title: "what",
      content: "\nTable of Contents\n\nsubmenuconfig\nWhat\nWhy\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nWhat\n\n\nSolAR is an open source framework dedicated to Augmented Reality (AR).\n\n\nIt offers a C++ SDK to easily and quickly develop and use custom solutions for camera pose estimation. It provides developers with a full chain from low-level vision components development to camera pose estimation pipelines and AR service development.\n\n\nThe SolAR framework is open-source and released under Apache license 2.0,\nthat lets you use it for research as well as for commercial purposes\naddressing various domains (smart factory, smart home, real estate,\nhealth, etc.).\n\n\nSolAR aims at stimulating the interaction between all actors of AR development for the benefit of end-users.\n\n\nA SolAR compatible Unity plugin is coming soon.\n\n\n\n\nWhy\n\n\nAR applications developers and end-users face a dilemma.\n\n\nOn one hand, major IT actors have released toolkits to develop AR applications. Nevertheless, they do not always meet the specific needs required by dedicated use cases or contextual environments (localization accuracy, lighting conditions, indoor/outdoor environments, tracking area range, dynamic scenes, etc.).\n\n\nNo solution fits all, and generally, these toolkits do not provide the level of tuning required to optimally adapt the vision based localization solution to the use case. Moreover, these closed solutions do not always ensure the confidentiality of data, and can store information concerning your environment (3D maps, key frames) or the augmentations (3D meshes, procedure scenarios) that could contain crucial intellectual property and private information.\n\n\nOn the other hand, open source vision libraries and SLAM implementations can generally be modified and configured to optimally meet AR applications requirements. However, many SLAM implementations generally developed by academic actors do not provide the license or the level of maturity required for the development of commercial solutions. Likewise, open source vision libraries offer a huge number of low-level functions but require a huge expertise and important development resources to obtain a usable camera pose estimation pipeline ready for commercial use.\n\n\nTo that end, SolAR offers an alternative to current commercial AR SDKs or existing open-source solutions, providing the benefits of both worlds – openness, ease of use, efficiency, adaptiveness. It aims at creating an ecosystem bringing researchers, developers, and end-users together to help the adoption of augmented reality.\n\n\n",
      id: 34
    });
    

  

    index.add({
      title: "how",
      content: "\nTable of Contents\n\nsubmenuconfig\nhow\nSolAR is open-source\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nhow\n\n\n\n\n\n\n\nThe SolAR Framework addresses the full chain of AR applications development:\n\n\n\n\nComponents creation: SolAR defines a unique API for basic components required for camera pose estimation (features extractor, descriptors calculation, matching, Perspective N Points, homography, image filters, etc.). The SolAR community can develop new components compliant with the SolAR API, whether royalty free or under a commercial license. To ease the publication of your SolAR components, you can embed them in containers.\n\n\nPipeline implementation of camera pose estimation: You can download containers of components published by the SolAR community. SolAR provides developers with a pipeline mechanism allowing to connect SolAR components to define your own camera pose estimation solution (today through a SDK, soon thanks to a dedicated graphic editor). When your pipeline is validated, you can publish it for AR applications developers.\n\n\nAR service development: By controlling the SolAR SDK directly from Unity, load the camera pose estimation solution developed by the SolAR community that best fits your application requirements. Simply develop your AR application as with any AR SDK and roll it out. Since SolAR is based on a unified interface, you will be able to easily make your application evolve with the new solutions developed by the SolAR community.\n\n\n\n\nThe following video presents these 3 steps in more detail:\n\n\n\n\nYour browser does not support the video tag.\n\n\n\n\n\n\nSolAR is open-source\n\n\nThis framework is open-source and released under Apache license 2.0,\nthat lets you use it for research as well as commercial purposes.\n\n\nNevertheless, only the SolAR framework is provided under Apache 2.0. The components you can use with the help of the framework to develop your own solution have their own license, which may not be compatible with Apache 2.0 or your own legal framework. Always check the compatibility of the components' licenses with themselves and with your own project. The SolAR community gives absolutely no warranty as to the legality of any solution that may result from your use of the framework, and cannot be held responsible for your use of the framework and of the components.\n\n\nAll components that are to be hosted on SolAR’s Github repositories must be released by their copyright holders under Apache 2.0, and can only make use of third-party software released under licenses compatible with Apache 2.0. Otherwise the components have to be externally hosted.\n\n\nb&lt;&gt;com and the SolAR community will try their best to review the components hosted on SolAR’s Github, but cannot warrant that all these components will respect the aforementioned conditions. Thus, you must always check the legal conditions of any component you intend to use.\n\n\n",
      id: 35
    });
    

  

    index.add({
      title: "who",
      content: "\nTable of Contents\n\nsubmenuconfig\nWho ?\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nWho ?\n\n\n\n\n\n\n\nThe SolAR initiative was launched by the b&lt;&gt;com Institute of Research and Technology, and is open to any contributors or users who share the SolAR goals.\n\n\nOur Contributors\n\n\n\n\n\n\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 36
    });
    

  

    index.add({
      title: "when",
      content: "\nTable of Contents\n\nsubmenuconfig\nSolAR roadmap\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nSolAR roadmap\n\n\nThe SolAR source code is going to be released for Windows and Linux in early November.\nIt will include the interface definition required to build simple camera pose estimation pipelines (samples will be given for natural image markers and fiducial markers) as well as a Unity plugin allowing AR service developers to create their first AR applications using SolAR.\n\n\nThe following roadmap presents the features that will be implemented in a near future on SolAR core (pipeline, multi-threading, openVX compliance, Android and iOS support, etc.) as well as the new expected components allowing the creation of extended camera pose estimation pipelines (SLAM, visual/inertial, depth sensor support, etc.).\n\n\nThis roadmap is a projection, and may be subject to modifications. Please contact us if you have any questions.\n\n\n\n\n\n\n\nAll contributions are welcome to bring about this roadmap!\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 37
    });
    

  

    index.add({
      title: "for whom",
      content: "\nTable of Contents\n\nsubmenuconfig\nFor whom is SolAR?\nSolAR applications\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nFor whom is SolAR?\n\n\n\n\nFor component developers, allowing them to create specific and optimized basic vision processing elements and share them with the community, either for free or not.\n\n\nFor pose estimation developers, allowing them to create a pose estimation pipeline with the best computer vision components available.\n\n\nFor AR service developers, allowing them to benefit from the best pose estimation pipelines for their AR applications.\n\n\n\n\n\n\nSolAR applications\n\n\nSolAR does not aim at focalizing on dedicated use cases, but rather offers a generic framework addressing all kinds of applications where AR can bring an added value:\n\n\n\n\nHome\n\n\n\nGaming, enhanced video contents, IoT interaction interface, etc.\n\n\n\n\n\nHealth services\n\n\n\nSurgery aid, rehabilitation, training, education, etc.\n\n\n\n\n\nIndustry\n\n\n\nAssembly, quality control, maintenance, factory planning, logistics, training, monitoring, sales and marketing, etc.\n\n\n\n\n\nReal estate\n\n\n\nConsultation, design, companion on construction sites, supervision, training, sales and marketing, etc.\n\n\n\n\n\nAnd much more.\n\n\n\n\n",
      id: 38
    });
    

  

    index.add({
      title: "programmer's guide",
      content: "\nTable of Contents\n\nsubmenuconfig\nThe programmer&#8217;s guide\nSolAR Overview\nSolAR Data Structures\nSolAR components interfaces\nSolAR components handling\nFrequently Asked Questions\nContact Mail\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nThe programmer&#8217;s guide\n\n\n\n\n\nSolAR Overview\n\n\nSolAR is a solution to easily and quickly implement custom camera pose estimation pipelines based on a set of vision and mathematics components in order to make them available to AR application developers.\n\n\nThe SolAR core handles everything that will allow the implementation of a pipeline:\n\n\n\n\nSolAR Data Structures define the information that flow in the pipelines and are exchanged between components.\n\n\nSolAR Components Interfaces define a standardized interface for the different categories of basic processing elements required to implement camera pose estimation (i.e.: key point extractor, descriptor computation, etc.). This unified interface is required to ensure interoperability between components allowing to easily swap one with another to improve the final camera pose estimation pipeline.\n\n\nThe SolAR Pipeline Manager handles the implementation of a pipeline by loading components, connecting them, and running the pipeline.\n\n\n\n\nThe SolAR Components are implementations of basic processing elements compliant with the SolAR components interfaces. Several components can implement the same component interface. In general, these components are created by wrapping computer vision libraries that could be either open-source (OpenCV, PCL, ROS, etc.) or proprietary. Each component can define its own parameters that will be used to fine tune the camera pose estimation solution.\n\n\n\n\n\n\n\n\n\nComing soon: configure components on the fly, pipeline, multithread, metadata.\n\n\n\n\n\n\nSolAR Data Structures\n\n\nThe SolAR pipeline consists of a chain of basic processing elements linked together so that the outputs of each element are the inputs of the next one. In order to provide modularity, SolAR specifies standard data structures defining the information exchanged between components required to implement a camera pose estimation solution.\n\n\nThe following categories describe the current SolAR data structures, with more to come.\n\n\nImage\n\nA SolAR image is an array of pixels where each pixel is defined by a set of color components coded with a given number of bits. Each pixel can be encoded with a dedicated colorimetric space (RGB, YUV, LAB, etc.). Contrary to OpenCV, an image is not just a matrix or an array. A SolAR image is clearly defined as an image object to ensure that a component waiting for an image as an input will not receive a random matrix such as a pose. Thus, an image is defined by:\n\n\n\n\nThe image size (width, height)\n\n\nThe image layout such as LAYOUT_GRB, LAYOUT_BGR, LAYOUT_GREY, LAYOUT_RGBA, LAYOUT_RGBX, LAYOUT_UNDEFINED\n\n\nThe pixel order either INTERLEAVED or PER_CHANNEL\n\n\nThe size of each color component, also called data type which can be either TYPE_8U, TYPE_16U, TYPE_32U, TYPE_64U\n\n\nA pointer to the raw data\n\n\n\n\nIn order to limit memory allocations and copies, which can drastically impact the efficiency of the camera pose estimation implementation, an image can point to the raw data instantiated by third party libraries such as OpenCV or OpenVX.\n\n\n\nMatrix\n\nThe SolAR implementation of matrices is based on the open source Eigen library for linear algebra. The SolAR framework redefines the following matrices:\n\n\n\n\nSolARVector4f  equates to a 4x1 matrix of floats\n\n\nSolARVector4d  equates to a 4x1 matrix of doubles\n\n\nSolARVector3f  equates to a 3x1 matrix of floats\n\n\nSolARVector3d  equates to a 3x1 matrix of doubles\n\n\nSolARTranslationVectorf equates to a 3x1 matrix of floats used to define a translation\n\n\nSolARPoint_3Df equates to a 3x1 matrix of floats used to define a 3D point\n\n\nSolARPoint_2Df equates to a 2x1 matrix of floats used to define a 2D point\n\n\nSolARPoseMatrixf equates to a 4x4 matrix of floats used to define a pose\n\n\nSolARMatrix33d equates to a 3x3 matrix of doubles\n\n\nSolARRotationMatrixf equates to a 3x3 matrix of floats used to define a rotation\n\n\nSolARQuaternionf equates to a Quaternion in floats used to define a rotation\n\n\n\n\n\nPose\n\nThe SolaARPose data structure is based on a standard row major homogeneous 4x4 matrix. Euler angles and quaternions can be directly extracted from this structure built using Eigen algorithms.\n\n\n\nMarker\n\nA SolAR Marker is a structure describing a convex area in a SolAR Image. A SolAR Marker allows managing different types of markers such ad fiducial markers or checker boards. It encodes shape and pose information as follows:\n\n\n\n\nEdges: a set of SolARPoint_2Df defining the convex area. A fiducial marker can be described with four edges. The order of the points is important and impacts the structure of the marker\n\n\nTranslation: a SolARVector3f defining the translation of the marker relative to the camera\n\n\nRotation: a SolARRotationMatrixf  defining the rotation of the marker relative to the camera\n\n\n\n\nThe SolAR Marker embeds information about the marker in a minimalist way. The reason is directly linked to the desired genericity across all the existing markers in the state-of-the-art methods.\n\n\n\nFeatures\n\nThe current implementation of the SolAR Features data structure takes advantage of the OpenCV Features2D definition. However, we are currently working on an abstract API to handle multiple keypoints, features descriptors and extractors implementations using technologies such as CUDA and OpenVX. We will be especially focusing on proper memory management and avoiding useless data copying.\n\n\nThe current SolAR Features data structure is not the final implementation we are aiming for and will be undergoing changes as we actively work on it.\n\n\n\n\n\nSolAR components interfaces\n\n\nSolAR components are vision or mathematics processing elements compliant with the SolAR component interface defined by the SolAR framework.\n\n\n\n\n\n\n\nAcquisition\n\nThe Acquisition Interface manages the capturing strategy from a given device and provides the input signal to the next processing component.\n\n\nImage\n\nThe ISolARCamera interface is dedicated to acquiring images from external device. It allows grabbing the current image and sets/extracts some parameters related to the projection and acquisition models as follows:\n\n\n\n\nget/set camera acquisition parameters: get default acquisition setting parameters (image size, frame rate..). The user can also set custom parameters which force the camera grabbing parameters to that value.\n\n\nget/set camera projection parameters: get camera projection parameters including camera matrix and distortion parameters. It assumes that camera is already correctly calibrated. The user can set these parameters by performing a preliminary calibration.\n\n\n\n\n\n\nConversion\n\nThe Conversion Interface manages conversion for different data structure.\n\n\nImage\n\nThe ISolaARImageConvertor performs the conversion between several image formats. It allows converting both color and type value using one unified method which automatically detects the color and/or type layers of the input and output.\n\n\n\n\nFiltering\n\nThe Filtering Interface manages filtering operations for different data structure.\n\n\nImage\n\nThe ISolARImageFilter is dedicated to perform various filtering operations assuming input/output consistency. The interface embeds the following operations:\n\n\n\n\nBinarizing\n\n\nEqualizing\n\n\nBlurring\n\n\nErosion\n\n\nDilation\n\n\nGradient\n\n\nLaplacian\n\n\n\n\n\nFeatures\n\nThe ISolARFeaturesFilter is dedicated to filter different extracted/computed features.\n\n\n\nMarkers\n\nThe ISolARMarkerFilter is dedicated to enhance marker filtering.\n\n\n\n\nEstimation\n\nThe Estimation Interface manages several pose estimation methods for cameras, objects and markers.\n\n\nFeatures\n\nThe ISolARKeypointDetector, ISolARDescriptorExtractor and ISolARDescriptorMatcher allow to detect geometrically relevant points in the image using known algorithms such as SURF or SIFT. (SURF, SIFT..). They also compute descriptors around these points and correlate sets of matches.\n\n\nThe ISolARHomographyFinder performs an homography transformation estimation and extracts a camera pose.\n\n\n\nMarker\n\nThe ISolARMarkerFinder allows to perform marker finding operations on different types of markers. It detects, segments and recognizes the marker and estimates its pose relative to the camera.\n\n\n\n\nSolAR Third Party Connector\n\nThe SolAR third party connector is a special SolAR Component used to exchange internal SolAR pose data with any third party outside of the SolAR framework. It is used to safely provide access to a SolAR Image and its associated SolAR Pose in a thread safe race free fashion. It internally implements a mutex locked circular buffer, allowing safe producer/consumer access. It allows synchronous and asynchronous read access for the consumer.\n\n\n\n\n\n\n\nThe internal buffer size of the container is currently set at one which means only the latest image and pose are available to the consumer at any given time. In the near future, SolAR will allow users to provide initialization parameters when creating components so the users will be able to specify the size of the buffer they desire.\n\n\nProducer\n\nAny component wishing to expose its pose data to an external third party must use a Third Party Connector. It can then use the set method to set the current SolAR Image and its associated SolAR Pose. The set method is thread safe and blocking. It will not return until the lock on the internal buffer is released by the reader.\n\n\n\nConsumer\n\nAny third party external to SolAR that needs access to internal pose data of a component must connect to its Third Party Connector. It can then use either the get method or the tryGet method to get the latest SolARImage and its associated SolARPose. The get method is thread safe and blocking. This means it will not return until there is available data to read and the lock on the internal buffer is released by the writer. The tryGet method is also thread safe but non blocking. It will return immediately after being called. It will return true if it was able to acquire the lock and read the data, or false if it was unable to obtain the lock or if there was nothing to read.\n\n\n\n\n\n\nSolAR components handling\n\n\nSolAR relies on the Cross Platform Component Framework (XPCF), a versatile framework that provides dynamic component instantiation and loading from modules. Basically, modules are libraries that collect components sharing a common element: purpose, framework, etc. XPCF also provides uniform component parametrization. Using XPCF, and thanks to the unified SolAR interfaces, it will be possible to build applications by picking and choosing different components in different modules at runtime without prior knowledge of the components when the application itself is compiled.\n\n\nFor more details, please refer to the XPCF website (coming soon).\n\n\n\n\nFrequently Asked Questions\n\n\n\n\nWhat is SolAR?\nSolAR is an open source initiative to develop a framework for pose estimation that can be used for Augmented Reality (AR) applications.\n\n\nWho initiated the SolAR project?\nThe b&lt;&gt;comInstitute of Research and Technology initiated the SolAR project after collecting the feedback of AR actors, AR end-users (industry, real-estate, medical, etc.), AR developers (essentially SMEs) and computer vision experts (academic researchers and research engineers from companies).\n\n\nWho can contribute to the SolAR project?\nAnyone can contribute to the SolAR project. Contributors only need to be proficient in C++ and computer vision skills.\n\n\nCan I use the SolAR framework for my AR applications?\nOf course! Just be wary of the licenses of the components used by the pose estimation pipelines you choose as each component can be under its own license, independently of the encompassing SolAR Apache v2 license.\n\n\n\n\n\n\nContact Mail\n\n\nFor any requests, please contact us.\n\n\n",
      id: 39
    });
    

  

    index.add({
      title: "legal notice",
      content: "\nTable of Contents\n\nsubmenuconfig\nLegal notice\n\n\n\nsubmenuconfig\n\n\n\n\nwhat\n\n\nhow\n\n\nwho\n\n\nwhen\n\n\nfor whom\n\n\nprogrammer&#8217;s guide\n\n\nlegal notice\n\n\n\n\n\n\nLegal notice\n\n\nSince the SolAR project is managed and hosted by the b&lt;&gt;com Institute of Research and Technology, it falls under their legal notice.\n\n\n",
      id: 40
    });
    

  

  
  
  

  
  
  

    index.add({
      title: "Fiducialmarker",
      content: "\nThis tutorial will walk you through the implementation of one of the first solution to do augmented reality: The fiducial marker. The tutorial will take approximately one hour to complete.\n\n\nPrerequisites\n\n\n\nA PC configured with the correct tools.\n\n\n\n\n\nProject files\n\n\n\nDownload the files required by the project.\n\n\nUnarchive the files to your desktop.\n\n\n\n\n\nFiducial pipeline overview\n\nFiducial markers are generally white and black 2D patterns that are easily identifiable in an image and that holds all information required to easily compute the pose of a camera that records it. They could be squared, circular, or defined by a set of binary points, and they have been and are still widely used as they offer robustness to estimate the pose of a camera for augmented reality applications. Fiducial maker based approaches are mostly build according to the following steps:\n\n\n\n\nInitialization: to load the fiducial marker and start the camera.\n\n\nDetection: to find fiducial patterns in the current image captured by the camera.\n\n\nRecognition: to select among the fiducial patterns detected in the current image the one we are looking for.\n\n\nCamera pose estimation: to estimate the position and orientation of the camera in the coordinate system of the fiducial marker.\n\n\n\n\nIn this tutorial, we focus on the squared binary marker based on pattern defined by a squared grid of black and white cells surrounded by a black border:\n\n\n\n\n\n\n\nIn our implementation, the number of cells in height and width must be similar, and the thickness of the border must be equal to the thickness of a cell of the pattern.\nWe will now provide much more details concerning the different components and how we will connect them to implement a pose estimation pipeline based on squared fiducial markers.\nThe following schema presents the full pipeline we will implement next:\n\n\n\n\n\nFigure 1. camera pose estimation pipeline based on a fiducial marker.\n\n\nThis pipeline seems quite complex, but you will see that its implementation  will take few minutes thanks to the SolAR framework. Following, we detail each component used during the four steps of our pipeline:\n\n\n\n\nInitialization step\n\n\n\nMarker2DSquaredBinary: This component load a file describing the squared binary marker. It is a yaml file defining the real size of the marker (including borders) in the user-defined unit (centimeter, meter, &#8230;&#8203;) as well as the squared binary pattern where 1 defined a white cell and 0 a black cell. Following, an example of file defining a squared binary marker:\n\n\n%YAML:1.0\n---\nMarkerWidth: 0.157\nMarkerHeight: 0.157\nPattern: !!opencv-matrix\n   rows: 6\n   cols: 6\n   dt: u\n   data: [ 1,0,0,0,1,1,1,0,0,1,1,1,1,1,0,1,0,1,0,0,1,0,0,1,1,0,0,1,1,0,1,1,1,0,0,1 ]\n\n\n\nThe user-defined unit have to be common for your whole pipeline, including camera calibration or for the unit defining your augmentations. For example, when you set the size of a cell of a chessboard used for camera calibration, be careful that this size is defined according to the same user-defined unit used for defining the marker size.\n\n\n\nDescriptorExtractorSBPattern: A squared binary pattern is represented by a matrix of Boolean, and this component simply concatenate each row of this matrix to create a vector of boolean (DescriptorBuffer) representing the descriptor of the squared binary pattern.\n\n\nCamera:  Now that the squared binary marker is loaded, we can create a camera component. This component load a file describing the intrinsic parameters of the camera estimated thanks to a calibration tool (here, add a link to this calibration tutorial). Without a good calibration, the pose estimated by this pipeline will be certainly wrong. Then, the component will start the camera by giving its id, and you can now get the current image by calling the nextImage() method in a loop.\n\n\n\n\n\nDetection step\n\n\n\nImageConvertor: This component convert the color image captured by the camera to a grey image.\n\n\nImageFilter: This component applies a filter to the image. Here, we apply a binarize filter to obtain a black and white (or binary) image. This filter requires a threshold between 0 and 255 to select if a grey pixel becomes black or white. If you set this threshold to -1, the threshold is automatically computed according to the OTSU method based on a histogram computed on the whole image. This filter is the weak point of this pipeline as the binarize threshold should be locally computed by region of the current image to reduce the impact of local specular reflections on the marker or overexposure.\n\n\nContoursExtractor: This component extracts contours from the previous binary image. In order to focus on contours of interest, we can set the minimum edges of the contours to 4.\n\n\nContoursFilterBinaryMarker: This component first keeps only contours that are closed and approximates low curves defined by a set of successive edges by a single edge. Then, it selects only contours with four edges. You can set the minimum size of the contours you want to keep (size defined in pixels) in order to exclude small quad contours.\n\n\nPerspectiveControllers: This component warps and crops the binary image to extract a set of sub-images whose borders are defined by the contours kept by the previous filter.\n\n\n\n\n\nRecognition step\n\n\n\nSBPatternDescriptorExtractor:  First, this component checks if each sub-image that have been created by the previous component corresponds to a squared binary marker (by detecting if the borders of the sub-image are black). Then, if this is the case then it extracts its squared binary pattern descriptors (by detecting the color of each cell of the pattern, and this for the four rotations of the sub-image).\n\n\nDescriptorMatcherRadius: This component compares the squared binary pattern of the marker we are looking for with the squared binary patterns extracted from the current image. It does it by computing the hamming distance between the descriptors.\n\n\nSBPatternReindexer: By setting in parameter the size of teh pattern (number of cells defining the pattern, for example 5 if it is a 5x5 pattern), and by knowing the contours extracted from the current image that match with the marker we are looking for, this component creates two vector of points: the first one with the 4 corners of the marker (in cells, meaning in the pattern space), and the second one with the 4 corners of the marker extracted from the image (in pixel, meaning in image space).\n\n\n\n\n\nCamera pose estimation step\n\n\n\nImage2WorldMapper4Marker2D: This component computes the 3D position of the four corners of the marker in the 3D coordinate system of the real space. To do that, we have to set as parameters the size of the pattern (in cells) as well as the size of the marker (in world unit defined by the user) to apply a cross-multiplication to the 4 corners of the marker given by the previous SBPatternReindexer component.\n\n\nPoseEstimation: This component applies a P4P (Perspective 4-Points) algorithm on the four corners of the marker to estimate the pose of the camera. This algorithm consists in solving the non-linear system that defines the pose of the camera knowing the position of 4 points in the real space as well as their projections in the image plane of the camera.\n\n\n\n\n\n\n\n\nInstructions\n\nInitialize your development project\n\nVisual Studio\n\nTo do\n===== QT Creator\nIf you are using QT Creator, open it and create a new project (in File menu). Choose \"Non-Qt project\" and \"Plain C++ Application\", set the location and the name of your project (for example SolARFiducialTutorial), and select as build system \"qmake\", and then the building kit of your choice. Finally, click on finish to create your project.\nNow, you need to select the file called \"SolARFiducialTutorial.pro\" in your project tree, and you have to add the following line before defining your source files:\n\n\n\nDEPENDENCIESCONFIG = sharedlib\ninclude ($$(BCOMDEVROOT)/builddefs/qmake/templateappconfig.pri)\n\n\n\nBe sure to have defined your environment variable $BCOMDEVROOT$ and to have copied in this folder all the files defining your build pipeline downloadable here. If not, download the zip file, unzip it, and copy the content of the folder builddefs-qmake-solar_v1.0.0 in $BCOMDEVROOT$/builddefs/qmake/.\n\n\nThen, create in your project folder a file called packagedependencies.txt and add in it your dependencies, namely the basic dependencies required by the SolARFramework (SolARFramework, xpcf, boost, eigen and spdlog) as well as the one required for the openCV module (SolARModuleOpencv and opencv):\n\n\n\nSolARFramework|1.0.0|SolARFramework|bcomBuild|url_repo_artifactory\nSolARContainerOpenCV|1.0.0|SolARContainerOpenCV|bcomBuild|url_repo_artifactory\nxpcf|1.0.0|xpcf|bcomBuild|http://repository.b-com.com/\nboost|1.64.0|boost|thirdParties|http://repository.b-com.com/\nopencv|3.2.0|opencv|thirdParties|http://repository.b-com.com/\nspdlog|1.0.0|spdlog|thirdParties|http://repository.b-com.com/\neigen|3.3.4|eigen|thirdParties|http://repository.b-com.com/amc-generic\n\n\n\nNow you can run QMake (click right of your project in QT creator, and click on run QMake). Every pathes for headers and library links are now set.\n\n\n\nmain.cpp\n\nFinally, replace the code of your main.cpp by the following one:\n\n\nmain.cpp\n\n#include &quot;SolARModuleManagerOpencv.h&quot;\n\nusing namespace std;\nusing namespace SolAR;\nnamespace xpcf  = org::bcom::xpcf;\n\nvoid run(int argc,char** argv){\n\n    // To redirect log to the console\n    LOG_ADD_LOG_TO_CONSOLE();\n\n    // ADD HERE: load your Opencv module\n\n    // ADD HERE: declarations and instantiation of components\n    // Example to declare and create a camera:\n    // SRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\n\n\n    // ADD HERE: declarations of data structures used to connect components\n    // Example to declare a SolARImage:\n    // SRef&lt;SolARImage&gt; inputImage;\n\n\n    // ADD HERE: Components configuration\n    // Generally through the method setParamerters of the components, except for the input components such as the camera or the marker that use specific methods to load configuration files\n\n\n    // ADD HERE: The pipeline loop\n\n}\n\nint printHelp(){\n        printf(&quot; usage :\\n&quot;);\n        printf(&quot; fiducialMarker.exe FiducialMarkerFilename CameraCalibrationFile VideoFile|cameraId configFile\\n\\n&quot;);\n        printf(&quot; Escape key to exit&quot;);\n        return 1;\n}\n\nint main(int argc, char *argv[])\n{\n    if(argc==3 || argc ==4){\n        run(argc,argv);\n        return 1;\n    }\n    else\n        return(printHelp());\n}\n\n\n\nAs you can see, the executable takes 4 arguments:\n\n\n\n\nThe url of a file describing the fiducial marker you are looking.\n\n\nThe url of the file defining the calibration of your camera (generate it with the calibration tool).\n\n\nThe Id of your camera.\n\n\nAnd finally, the configuration file defining where are the registery files and the dll pathes of the modules used in your sample (here we only need SolARModuleOpencv). An example of configuration file is available here.\n\n\n\n\nDownload and copy in your project folder the files describing the fiducial marker as well as the configuration file (here) and update this last with the good pathes. Similarly, copy the camera calibration file generate by the calibration tool in your project folder.\n\n\nNow, in your IDE, you can set the command line arguments of your executable with pathes relative to your executable folder:\n\n\n\n\nfiducialMarker.yml camera_calibration.yml 0 config.ini\n\n\n\n\nYour development environment is now ready, now you just need to fill the main.cpp.\n\n\n\nLoad your module(s)\n\nThis is very simple. Create a SolARModuleManagerOpencv, set as constructor argument the url of the configuration file of the Opencv module (pass as the fourth argument of your executable).\n\n\nmain.cpp\n\n// ADD HERE: load your Opencv module\nSolARModuleManagerOpencv opencvModule(argv[4]);\nif (!opencvModule.isLoaded()) // xpcf library load has failed\n{\n    LOG_ERROR(&quot;XPCF library load has failed&quot;)\n    return;\n}\n\n\n\nThat is done, now you can easily instantiate any components embedded in the module.\n\n\n\nComponents declaration and instanciation\n\nThe goal here is to declare and instanciate all components you will need for the camera pose estimation based on fiducial marker.\nIn the main.cpp, you can find in comment how to easily declare and instanciate a camera component:\n\n\ntitle\n\nSRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\n\n\n\nYou can do it now for all 12 components of the pipeline described in figure 1  (SolARDescriptorsExtractorSBPattern is used twice, but can be instantiated only once).\n\n\nmain.cpp\n\n// ADD HERE: declarations and instantiation of components\n// Example to declare and create a camera:\n// SRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent(UUID::OPENCV::CAMERA);\nSRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\nSRef&lt;ISolARMarker2DSquaredBinary&gt; binaryMarker = opencvModule.createComponent&lt;ISolARMarker2DSquaredBinary&gt;(UUID::OPENCV::MARKER2D_SQUARED_BINARY);\nSRef&lt;ISolARImageViewer&gt; imageViewerFilteredContours = opencvModule.createComponent&lt;ISolARImageViewer&gt;(UUID::OPENCV::IMAGE_VIEWER);\nSRef&lt;ISolARImageFilter&gt; imageFilter = opencvModule.createComponent&lt;ISolARImageFilter&gt;(UUID::OPENCV::IMAGE_FILTER);\nSRef&lt;ISolARImageConvertor&gt; imageConvertor = opencvModule.createComponent&lt;ISolARImageConvertor&gt;(UUID::OPENCV::IMAGE_CONVERTOR);\nSRef&lt;ISolARContoursExtractor&gt; contoursExtractor = opencvModule.createComponent&lt;ISolARContoursExtractor&gt;(UUID::OPENCV::CONTOURS_EXTRACTOR);\nSRef&lt;ISolARContoursFilter&gt; contoursFilter = opencvModule.createComponent&lt;ISolARContoursFilter&gt;(UUID::OPENCV::CONTOURS_FILTER_BINARY_MARKER);\nSRef&lt;ISolARPerspectiveController&gt; perspectiveController = opencvModule.createComponent&lt;ISolARPerspectiveController&gt;(UUID::OPENCV::PERSPECTIVE_CONTROLLER);\nSRef&lt;ISolARDescriptorsExtractorSBPattern&gt; patternDescriptorExtractor = opencvModule.createComponent&lt;ISolARDescriptorsExtractorSBPattern&gt;(UUID::OPENCV::DESCRIPTORS_EXTRACTOR_SBPATTERN);\nSRef&lt;ISolARDescriptorMatcher&gt; patternMatcher = opencvModule.createComponent&lt;ISolARDescriptorMatcher&gt;(UUID::OPENCV::DESCRIPTOR_MATCHER_RADIUS);\nSRef&lt;ISolARSBPatternReIndexer&gt; patternReIndexer = opencvModule.createComponent&lt;ISolARSBPatternReIndexer&gt;(UUID::OPENCV::SBPATTERN_REINDEXER);\nSRef&lt;ISolARImage2WorldMapper&gt; img2worldMapper = opencvModule.createComponent&lt;ISolARImage2WorldMapper&gt;(UUID::OPENCV::IMAGE2WORLD_MAPPER);\nSRef&lt;ISolARPoseEstimation&gt; PnP = opencvModule.createComponent&lt;ISolARPoseEstimation&gt;(UUID::OPENCV::POSE_ESTIMATION);\n\n\n\n\nData structures declaration\n\nYour components will exchange data through data structures when running the pipeline. You need to declare all those shown in figure 1.\n\n\nmain.cpp\n\n// ADD HERE: declarations of data structures used to connect components\n// Example to declare a SolARImage:\n// SRef&lt;SolARImage&gt; inputImage;\n\nSRef&lt;SolARImage&gt; inputImage;\nSRef&lt;SolARImage&gt; greyImage  = xpcf::utils::make_shared&lt;SolARImage&gt;(SolARImage::ImageLayout::LAYOUT_GREY,\n                                 SolARImage::PixelOrder::INTERLEAVED,SolARImage::DataType::TYPE_8U); (1)\nSRef&lt;SolARImage&gt; binaryImage  = xpcf::utils::make_shared&lt;SolARImage&gt;(SolARImage::ImageLayout::LAYOUT_GREY,\n                                 SolARImage::PixelOrder::INTERLEAVED,SolARImage::DataType::TYPE_8U); (1)\n\nSRef&lt;SolARImage&gt; contoursImage;\nSRef&lt;SolARImage&gt; filteredContoursImage;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              contours;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              filtered_contours;\nstd::vector&lt;SRef&lt;SolARImage&gt;&gt;                   patches;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              recognizedContours;\nSRef&lt;SolARDescriptorBuffer&gt;                     recognizedPatternsDescriptors;\nSRef&lt;SolARDescriptorBuffer&gt;                     markerPatternDescriptor;\nstd::vector&lt;SolARDescriptorMatch&gt;               patternMatches;\nstd::vector&lt;SRef&lt;SolARPoint2Df&gt;&gt;                pattern2DPoints;\nstd::vector&lt;SRef&lt;SolARPoint2Df&gt;&gt;                img2DPoints;\nstd::vector&lt;SRef&lt;SolARPoint3Df&gt;&gt;                pattern3DPoints;\nSolARPose                                       pose;\n\nSolARCamCalibration K;\nSolARCamDistortion camDist;\n\n\n\n\n\n1\nhere, the image converter and filter do not yet instantiate the output image, so you need to do it yourself.\n\n\n\n\n\nComponents configuration\n\nTo complete\n\n\nmain.cpp\n\n// ADD HERE: Components configuration\n// Generally through the method setParamerters of the components, except for the input components such as the camera or the marker that use specific methods to load configuration files\n\nbinaryMarker-&gt;loadMarker(argv[1]);\npatternDescriptorExtractor-&gt;extract(binaryMarker-&gt;getPattern(), markerPatternDescriptor);\n\nint minContourSize = 4;\ncontoursExtractor-&gt;setParameters(minContourSize);\n\nint minContourLength = 20;\ncontoursFilter-&gt;setParameters(minContourLength);\n\nSolARSizei CorrectedImagesSize = {640,480};\nperspectiveController-&gt;setParameters(CorrectedImagesSize);\n\nint patternSize = binaryMarker-&gt;getPattern()-&gt;getSize();\npatternDescriptorExtractor-&gt;setParameters(patternSize);\n\npatternReIndexer-&gt;setParameters(patternSize);\n\nSolARSizei sbPatternSize;\nsbPatternSize.width = patternSize;\nsbPatternSize.height = patternSize;\nimg2worldMapper-&gt;setParameters(sbPatternSize, binaryMarker-&gt;getSize());\n\n//Load camera parameters and start it\ncamera-&gt;loadCameraParameters(argv[2]);\n\nPnP-&gt;setCameraParameters(camera-&gt;getIntrinsicsParameters(), camera-&gt;getDistorsionParameters());\noverlay3D-&gt;setCameraParameters(camera-&gt;getIntrinsicsParameters(), camera-&gt;getDistorsionParameters());\n\nif (camera-&gt;start(atoi(argv[3])) != FrameworkReturnCode::_SUCCESS) // Camera\n{\n    LOG_ERROR (&quot;Camera with id {} does not exist&quot;, argv[3]);\n    return ;\n}\n\n\n\n\nThe pipeline loop\n\nTo complete\n\n\nmain.cpp\n\nbool process = true;\nwhile (process)\n{\n  if(camera-&gt;getNextImage(inputImage)==SolAR::FrameworkReturnCode::_ERROR_)\n       break;\n\n  // Convert Image from RGB to grey\n  imageConvertor-&gt;convert(inputImage, greyImage);\n\n  // Convert Image from grey to black and white\n  imageFilter-&gt;binarize(greyImage,binaryImage,-1,255);\n\n  // Extract contours from binary image\n  contoursExtractor-&gt;extract(binaryImage,contours);\n\n  // Filter 4 edges contours to find those candidate for marker contours\n  contoursFilter-&gt;filter(contours, filtered_contours);\n\n  // Create one warpped and cropped image by contour\n  perspectiveController-&gt;correct(binaryImage, filtered_contours, patches);\n\n  // test if this last image is really a squared binary marker, and if it is the case, extract its descriptor\n   if (patternDescriptorExtractor-&gt;extract(patches, filtered_contours, recognizedPatternsDescriptors, recognizedContours) != FrameworkReturnCode::_ERROR_)\n   {\n       // From extracted squared binary pattern, match the one corresponding to the squared binary marker\n       if (patternMatcher-&gt;match(markerPatternDescriptor, recognizedPatternsDescriptors, patternMatches) == SolAR::DescriptorMatcher::DESCRIPTORS_MATCHER_OK)\n       {\n\n           // Reindex the pattern to create two vector of points, the first one corresponding to marker corner, the second one corresponding to the poitsn of the contour\n           patternReIndexer-&gt;reindex(recognizedContours, patternMatches, pattern2DPoints, img2DPoints);\n\n           // Compute the 3D position of each corner of the marker\n           img2worldMapper-&gt;map(pattern2DPoints, pattern3DPoints);\n\n           // Compute the pose of the camera using a Perspective n Points algorithm using only the 4 corners of the marker\n           if (PnP-&gt;poseFromSolvePNP(pose, img2DPoints, pattern3DPoints) == FrameworkReturnCode::_SUCCESS)\n           {\n               LOG_INFO(&quot;Pose: {}&quot;, pose);\n           }\n       }\n   }\n}\n\n\n\n\nDisplay a cube\n\nto complete\n\n\n\n",
      id: 41
    });
    

  

    index.add({
      title: "installation",
      content: "downloads\n\nsubmenuconfig\n\n\n\n\ninstallation\n\n\nsamples\n\n\ntutorials\n\n\ntools\n\n\n\n\n\n\nSolarFramework Installer for windows\n\n\nA SolAR Framework Windows installer is provided in order to quickly install:\n\n\n\n\nthe SolARFramework library (debug and release modes) and interfaces (C++ header files)\n\n\nSolAR modules libraries (debug and release modes) and interfaces (C++ header files)\n\n\nthe required third party libraries (debug and release modes) and third party interfaces (C++ header files)\n\n\nthe QT creator pre-requisites\n\n\nSolAR samples (C++ sample code)\n\n\n\n\nThe installer can be downloaded here:\n\n\nhttps://github.com/SolarFramework/binaries/releases/download/SolARFramework-installer%2F0.2%2Fwin/SolarFramework-installer.exe\n\n\nUsing the installer is straightforward:\n\n\n\n\ndownload then launch the installer\n\n\nread then accept the license agreement, then press \"Next\"\n\n\n\n\n\n\n\n\n\n\nPlease close QT on your computer, before executing the installer.\n\n\n\n\n\n\n\n\n\n\n\n\nselect the destination installation folder (default is: C:\\SolARFramework).\n\n\n\n\n\n\n\n\n\n\n\nselect the components you want to install.\n\n\n\n\n\n\n\n\n\nRegarding this last step, you have the choice between:\n\n\n\n\nSolAR libraries: this will install SolAR Framework and SolAR modules libraries and interfaces only. Additionnaly this will install\na SolAR component manager (xpcf) used by SolAR to load SolAR modules on the fly, and to instantiate components contained by modules\n\n\nQT creator dependencies: this will install a windows version of pkg-config program, used by SolAR build scripts to generate Makefiles under QT creator\n\n\nThird party libraries: this will install the following third party libraries and interfaces: opencv, boost, eigen and spdlog\n\n\nSample code: this will create a Samples folder under your SolARFramework installation folder. This folder contains sample C++ projects that you can use\nto learn the basics of SolAR.\n\n\n\n\nPlease use the default values: it will install everything you need to use SolAR, especially if you want to first test a sample code.\n\n\n\n\nFrequently Asked Questions\n\n\n\n\nWhen I run the installer, it asks me to  update pkgconfig, do I need to accept? \nyes, please accpet it will uninstall the current version and replace by a new one.\n\n\n\n\n",
      id: 42
    });
    

  

    index.add({
      title: "samples",
      content: "\nTable of Contents\n\nsubmenuconfig\nSamples\nPrerequesite\nSample project configuration\nFrequently Asked Questions\n\n\n\nsubmenuconfig\n\n\n\n\ninstallation\n\n\nsamples\n\n\ntutorials\n\n\ntools\n\n\n\n\n\n\nSamples\n\n\n\n\n\nPrerequesite\n\n\nYou should have first installed SolAR binaries, please refer to the binaries part .\n\n\nPlease check your SolAR directory :\n\n\n\n\n\n\n\nThe \"Sample\" directory contains the sample programs available for SolAR.\n\n\n\n\nSample project configuration\n\n\nThe sample codes are installed ith the binaries.\n\n\nPlease choose the sample code you are interested in ond open the corresponding directory.\n\n\nThen open the project .pro file with QT creator.\n\n\nCompile\n\nPlease click on \"run qmake\" : it will configure the compilation to your config parameters (set during the SolAR installation).\n\n\n\n\n\n\n\nThen click on \"build\" and check the sample code is correctly compiled.\n\n\n\n\n\n\n\n\nRun it\n\nYou then have to configure your run parameters directory to use the current folder (the sample code is given with files expected in parameters).\nOn QT creator, it means selecting the \"project/runs tab\" and then configure the working directory containing the readme.adoc and images files.\nFor instance, for the dynamic Natural Imahge Marker sample, please configure your \"&#8230;&#8203;/Samples/NaturalImageMarker/Dynamic\" directory.\n\n\n\n\n\n\n\nYou also have to indicate the parameters of the sample code for running. The readme.adoc can help you to understand.\n\n\n\n\n\n\n\n\nNatural Marker samples\n\nHere is an example of Natural Image Marker based on SolAR.\n\n\nUse this sample to know more about the pipeline manager used in SolAR, with features equivalent to the simple mode. It will help you to understand the basic concepts of the powerful pipeline manager.\n\n\nTo use it, you can print the NaturalImage \"graf1.png\" present in the static directory and orientate your camera in its direction, either point your camera on your computer displaying it (the sample code displays the natural image), as illustraed here.\n\n\nRead the instructions below to know how to open and run the Natural Marker sample project.\n\n\n\n\n\n\n\n\n\nIf you use QT creator, open the .pro file and configure your project as usual (see \"getting started\").\nHave a look at the \"main.cpp\" file, which is clearly commented and explained step by step.\nThe difference in this program, compared to the \"simple\" sample, is the use of the XPCF pipeline manager . This is not usefull or necessary if you want to use libraries in static modes, but it is interesting to look at it if you plan to use the dynamic mode.\n\n\nNOTE : cette partie doit être complétée.\nYou can see that unique identifiers are used for component creations.\nYou need to include TheComponentUsed.h in your program, as the component structure should be known for coompilation\n(you can find more information about XPCF on the XPCF web site)\n\n\n\n\n\n\n\nFrequently Asked Questions\n\n\n\n\nWhen I compile the sample code, I obtain the error \"error: C2039: 'TOOLS': is not a member of 'SolAR::MODULES'\": what is the problem? \nIt probably means that your SolAR binaries are not up-to-date, try to close QT, and  re install SolAR see the binaries part.\n\n\nWhen I compile the sample code, I obtain the error \n\"SolARCameraOpencv.h\" does not exist. This is probably due to a environment parameter problem. Please close and re open QT, and retry. Check your SolAR directory, as advised in this section.\n\n\nWhen I run the sample code, I see \"File readme.adoc does not exist\", what does it mean? \nIt means your working directory for this sample is not configured properly. See the \"sample configuration\" sub section.\n\n\nWhen I run the sample code, I see \"missing parameters\", what does it mean? \nIt means your project run configuration have some missing parameters. The missing parameters are described in the console log, and in the readme.adoc in the sample directory. See the \"sample configuration\" sub section for details.\n\n\n\n\n",
      id: 43
    });
    

  

    index.add({
      title: "tutorials",
      content: "tutorials\n\nTable of Contents\n\nsubmenuconfig\nTutorials\nlevel 1 : simple\nlevel 2 : static\nlevel 3 : dynamic\n#4 Fiducial Marker\n\n\n\nsubmenuconfig\n\n\n\n\ninstallation\n\n\nsamples\n\n\ntutorials\n\n\ntools\n\n\n\n\n\n\nTutorials\n\n\n\n\n\nlevel 1 : simple\n\n\nTutorial on a Natural Image Marker program\n\nFor the three versions of it, you can see a visual feedback of natural marker estimation.\n\n\nTable 1. Advantages and drawbacks of different modes\n\n\n\n\n\n\n\nType\nAdvantages\nDrawbacks\n\n\n\n\nDynamic Mode\nItem 3\ndraw2\n\n\n\n\nSimple Mode\nvery symple notions, easy development\nall libraries are loaded even if not used\n\n\nStatic Mode\nad 1\ndraw2\n\n\n\n\nTo use it, you can either : print the NaturalImage marker file and orientate your camera in its direction, either point your camera on your computer displaying it (the sample code displays the natural image), as illustraed here.\n\n\n\n\n\n\n\nYou can choose on of those ways to programs a natural marker sample :\n\n\n\n\nlevel 1 : simple mode : use this sample for your first SolAR application. The notions of managing components is as simple as possible.\n\n\n\n\nlink: http://forge.b-com.com/git/argo/SolAR/Samples/NaturalImageMarker.git\n\n\n\n\nOpen the \"Simple\" folder.\nIf you use QT, open the .pro file and configure your project as usual (see \"getting started\").\n\n\nHave a look at the \"main.cpp\" file, which is clearly commented and explained step by step.\n\n\n\n\n\n\nlevel 3 : dynamic mode : use this sample to benefit of the best of the SolAR pipeline manager. It will help you to understand the basic concepts of this powerful tool, and you will be able to load components in dynamic mode.If you have no intent to use SolAR in dynamic mode, you don&#8217;t need to use the level 3.\n\n\n\n\nlink: http://forge.b-com.com/git/argo/SolAR/Samples/NaturalImageMarker.git\n\n\n\n\nOpen the \"Dynamic\" folder.\nIf you use QT, open the .pro file and configure your project as usual (see \"getting started\").\nHave a look at the \"main.cpp\" file, which is clearly commented and explained step by step.\n\n\nYou can see that unique identifiers are used for component creations.\nYou don&#8217;t need to include TheComponentUsed.h in your program, but you need to instantiate a module manager\n(you can find more information about XPCF on the XPCF web site)\n\n\n\n\ntutorial\n\n:include _NaturalImageMarkersimpletuto[Natural Image Marker Simple sample code]\n\n\n\nexercise\n\n\n\nexercise correction\n\n\n\n\n\n\nlevel 2 : static\n\n\nTutorial on a Natural Image Marker program\n\ntutorial\n\n:include _NaturalImageMarkerstatictuto[Natural Image Marker Simple sample code]\n\n\n\nexercise\n\n\n\nexercise correction\n\n\n\n\n\n\nlevel 3 : dynamic\n\n\nTutorial on a Natural Image Marker program\n\ntutorial\n\n:include _NaturalImageMarkerdynamicetuto[Natural Image Marker Simple sample code]\n\n\n\nexercise\n\n\n\nexercise correction\n\n\n\n\n\n\n#4 Fiducial Marker\n\n\nThis tutorial will walk you through the implementation of one of the first solution to do augmented reality: The fiducial marker. The tutorial will take approximately one hour to complete.\n\n\nPrerequisites\n\n\n\nA PC configured with the correct tools.\n\n\n\n\n\nProject files\n\n\n\nDownload the files required by the project.\n\n\nUnarchive the files to your desktop.\n\n\n\n\n\nFiducial pipeline overview\n\nFiducial markers are generally white and black 2D patterns that are easily identifiable in an image and that holds all information required to easily compute the pose of a camera that records it. They could be squared, circular, or defined by a set of binary points, and they have been and are still widely used as they offer robustness to estimate the pose of a camera for augmented reality applications. Fiducial maker based approaches are mostly build according to the following steps:\n\n\n\n\nInitialization: to load the fiducial marker and start the camera.\n\n\nDetection: to find fiducial patterns in the current image captured by the camera.\n\n\nRecognition: to select among the fiducial patterns detected in the current image the one we are looking for.\n\n\nCamera pose estimation: to estimate the position and orientation of the camera in the coordinate system of the fiducial marker.\n\n\n\n\nIn this tutorial, we focus on the squared binary marker based on pattern defined by a squared grid of black and white cells surrounded by a black border:\n\n\n\n\n\n\n\nIn our implementation, the number of cells in height and width must be similar, and the thickness of the border must be equal to the thickness of a cell of the pattern.\nWe will now provide much more details concerning the different components and how we will connect them to implement a pose estimation pipeline based on squared fiducial markers.\nThe following schema presents the full pipeline we will implement next:\n\n\n\n\n\nFigure 1. camera pose estimation pipeline based on a fiducial marker.\n\n\nThis pipeline seems quite complex, but you will see that its implementation  will take few minutes thanks to the SolAR framework. Following, we detail each component used during the four steps of our pipeline:\n\n\n\n\nInitialization step\n\n\n\nMarker2DSquaredBinary: This component load a file describing the squared binary marker. It is a yaml file defining the real size of the marker (including borders) in the user-defined unit (centimeter, meter, &#8230;&#8203;) as well as the squared binary pattern where 1 defined a white cell and 0 a black cell. Following, an example of file defining a squared binary marker:\n\n\n%YAML:1.0\n---\nMarkerWidth: 0.157\nMarkerHeight: 0.157\nPattern: !!opencv-matrix\n   rows: 6\n   cols: 6\n   dt: u\n   data: [ 1,0,0,0,1,1,1,0,0,1,1,1,1,1,0,1,0,1,0,0,1,0,0,1,1,0,0,1,1,0,1,1,1,0,0,1 ]\n\n\n\nThe user-defined unit have to be common for your whole pipeline, including camera calibration or for the unit defining your augmentations. For example, when you set the size of a cell of a chessboard used for camera calibration, be careful that this size is defined according to the same user-defined unit used for defining the marker size.\n\n\n\nDescriptorExtractorSBPattern: A squared binary pattern is represented by a matrix of Boolean, and this component simply concatenate each row of this matrix to create a vector of boolean (DescriptorBuffer) representing the descriptor of the squared binary pattern.\n\n\nCamera:  Now that the squared binary marker is loaded, we can create a camera component. This component load a file describing the intrinsic parameters of the camera estimated thanks to a calibration tool (here, add a link to this calibration tutorial). Without a good calibration, the pose estimated by this pipeline will be certainly wrong. Then, the component will start the camera by giving its id, and you can now get the current image by calling the nextImage() method in a loop.\n\n\n\n\n\nDetection step\n\n\n\nImageConvertor: This component convert the color image captured by the camera to a grey image.\n\n\nImageFilter: This component applies a filter to the image. Here, we apply a binarize filter to obtain a black and white (or binary) image. This filter requires a threshold between 0 and 255 to select if a grey pixel becomes black or white. If you set this threshold to -1, the threshold is automatically computed according to the OTSU method based on a histogram computed on the whole image. This filter is the weak point of this pipeline as the binarize threshold should be locally computed by region of the current image to reduce the impact of local specular reflections on the marker or overexposure.\n\n\nContoursExtractor: This component extracts contours from the previous binary image. In order to focus on contours of interest, we can set the minimum edges of the contours to 4.\n\n\nContoursFilterBinaryMarker: This component first keeps only contours that are closed and approximates low curves defined by a set of successive edges by a single edge. Then, it selects only contours with four edges. You can set the minimum size of the contours you want to keep (size defined in pixels) in order to exclude small quad contours.\n\n\nPerspectiveControllers: This component warps and crops the binary image to extract a set of sub-images whose borders are defined by the contours kept by the previous filter.\n\n\n\n\n\nRecognition step\n\n\n\nSBPatternDescriptorExtractor:  First, this component checks if each sub-image that have been created by the previous component corresponds to a squared binary marker (by detecting if the borders of the sub-image are black). Then, if this is the case then it extracts its squared binary pattern descriptors (by detecting the color of each cell of the pattern, and this for the four rotations of the sub-image).\n\n\nDescriptorMatcherRadius: This component compares the squared binary pattern of the marker we are looking for with the squared binary patterns extracted from the current image. It does it by computing the hamming distance between the descriptors.\n\n\nSBPatternReindexer: By setting in parameter the size of teh pattern (number of cells defining the pattern, for example 5 if it is a 5x5 pattern), and by knowing the contours extracted from the current image that match with the marker we are looking for, this component creates two vector of points: the first one with the 4 corners of the marker (in cells, meaning in the pattern space), and the second one with the 4 corners of the marker extracted from the image (in pixel, meaning in image space).\n\n\n\n\n\nCamera pose estimation step\n\n\n\nImage2WorldMapper4Marker2D: This component computes the 3D position of the four corners of the marker in the 3D coordinate system of the real space. To do that, we have to set as parameters the size of the pattern (in cells) as well as the size of the marker (in world unit defined by the user) to apply a cross-multiplication to the 4 corners of the marker given by the previous SBPatternReindexer component.\n\n\nPoseEstimation: This component applies a P4P (Perspective 4-Points) algorithm on the four corners of the marker to estimate the pose of the camera. This algorithm consists in solving the non-linear system that defines the pose of the camera knowing the position of 4 points in the real space as well as their projections in the image plane of the camera.\n\n\n\n\n\n\n\n\nInstructions\n\nInitialize your development project\n\nVisual Studio\n\nTo do\n===== QT Creator\nIf you are using QT Creator, open it and create a new project (in File menu). Choose \"Non-Qt project\" and \"Plain C++ Application\", set the location and the name of your project (for example SolARFiducialTutorial), and select as build system \"qmake\", and then the building kit of your choice. Finally, click on finish to create your project.\nNow, you need to select the file called \"SolARFiducialTutorial.pro\" in your project tree, and you have to add the following line before defining your source files:\n\n\n\nDEPENDENCIESCONFIG = sharedlib\ninclude ($$(BCOMDEVROOT)/builddefs/qmake/templateappconfig.pri)\n\n\n\nBe sure to have defined your environment variable $BCOMDEVROOT$ and to have copied in this folder all the files defining your build pipeline downloadable here. If not, download the zip file, unzip it, and copy the content of the folder builddefs-qmake-solar_v1.0.0 in $BCOMDEVROOT$/builddefs/qmake/.\n\n\nThen, create in your project folder a file called packagedependencies.txt and add in it your dependencies, namely the basic dependencies required by the SolARFramework (SolARFramework, xpcf, boost, eigen and spdlog) as well as the one required for the openCV module (SolARModuleOpencv and opencv):\n\n\n\nSolARFramework|1.0.0|SolARFramework|bcomBuild|url_repo_artifactory\nSolARContainerOpenCV|1.0.0|SolARContainerOpenCV|bcomBuild|url_repo_artifactory\nxpcf|1.0.0|xpcf|bcomBuild|http://repository.b-com.com/\nboost|1.64.0|boost|thirdParties|http://repository.b-com.com/\nopencv|3.2.0|opencv|thirdParties|http://repository.b-com.com/\nspdlog|1.0.0|spdlog|thirdParties|http://repository.b-com.com/\neigen|3.3.4|eigen|thirdParties|http://repository.b-com.com/amc-generic\n\n\n\nNow you can run QMake (click right of your project in QT creator, and click on run QMake). Every pathes for headers and library links are now set.\n\n\n\nmain.cpp\n\nFinally, replace the code of your main.cpp by the following one:\n\n\nmain.cpp\n\n#include &quot;SolARModuleManagerOpencv.h&quot;\n\nusing namespace std;\nusing namespace SolAR;\nnamespace xpcf  = org::bcom::xpcf;\n\nvoid run(int argc,char** argv){\n\n    // To redirect log to the console\n    LOG_ADD_LOG_TO_CONSOLE();\n\n    // ADD HERE: load your Opencv module\n\n    // ADD HERE: declarations and instantiation of components\n    // Example to declare and create a camera:\n    // SRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\n\n\n    // ADD HERE: declarations of data structures used to connect components\n    // Example to declare a SolARImage:\n    // SRef&lt;SolARImage&gt; inputImage;\n\n\n    // ADD HERE: Components configuration\n    // Generally through the method setParamerters of the components, except for the input components such as the camera or the marker that use specific methods to load configuration files\n\n\n    // ADD HERE: The pipeline loop\n\n}\n\nint printHelp(){\n        printf(&quot; usage :\\n&quot;);\n        printf(&quot; fiducialMarker.exe FiducialMarkerFilename CameraCalibrationFile VideoFile|cameraId configFile\\n\\n&quot;);\n        printf(&quot; Escape key to exit&quot;);\n        return 1;\n}\n\nint main(int argc, char *argv[])\n{\n    if(argc==3 || argc ==4){\n        run(argc,argv);\n        return 1;\n    }\n    else\n        return(printHelp());\n}\n\n\n\nAs you can see, the executable takes 4 arguments:\n\n\n\n\nThe url of a file describing the fiducial marker you are looking.\n\n\nThe url of the file defining the calibration of your camera (generate it with the calibration tool).\n\n\nThe Id of your camera.\n\n\nAnd finally, the configuration file defining where are the registery files and the dll pathes of the modules used in your sample (here we only need SolARModuleOpencv). An example of configuration file is available here.\n\n\n\n\nDownload and copy in your project folder the files describing the fiducial marker as well as the configuration file (here) and update this last with the good pathes. Similarly, copy the camera calibration file generate by the calibration tool in your project folder.\n\n\nNow, in your IDE, you can set the command line arguments of your executable with pathes relative to your executable folder:\n\n\n\n\nfiducialMarker.yml camera_calibration.yml 0 config.ini\n\n\n\n\nYour development environment is now ready, now you just need to fill the main.cpp.\n\n\n\nLoad your module(s)\n\nThis is very simple. Create a SolARModuleManagerOpencv, set as constructor argument the url of the configuration file of the Opencv module (pass as the fourth argument of your executable).\n\n\nmain.cpp\n\n// ADD HERE: load your Opencv module\nSolARModuleManagerOpencv opencvModule(argv[4]);\nif (!opencvModule.isLoaded()) // xpcf library load has failed\n{\n    LOG_ERROR(&quot;XPCF library load has failed&quot;)\n    return;\n}\n\n\n\nThat is done, now you can easily instantiate any components embedded in the module.\n\n\n\nComponents declaration and instanciation\n\nThe goal here is to declare and instanciate all components you will need for the camera pose estimation based on fiducial marker.\nIn the main.cpp, you can find in comment how to easily declare and instanciate a camera component:\n\n\ntitle\n\nSRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\n\n\n\nYou can do it now for all 12 components of the pipeline described in figure 1  (SolARDescriptorsExtractorSBPattern is used twice, but can be instantiated only once).\n\n\nmain.cpp\n\n// ADD HERE: declarations and instantiation of components\n// Example to declare and create a camera:\n// SRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent(UUID::OPENCV::CAMERA);\nSRef&lt;ISolARCamera&gt; camera = opencvModule.createComponent&lt;ISolARCamera&gt;(UUID::OPENCV::CAMERA);\nSRef&lt;ISolARMarker2DSquaredBinary&gt; binaryMarker = opencvModule.createComponent&lt;ISolARMarker2DSquaredBinary&gt;(UUID::OPENCV::MARKER2D_SQUARED_BINARY);\nSRef&lt;ISolARImageViewer&gt; imageViewerFilteredContours = opencvModule.createComponent&lt;ISolARImageViewer&gt;(UUID::OPENCV::IMAGE_VIEWER);\nSRef&lt;ISolARImageFilter&gt; imageFilter = opencvModule.createComponent&lt;ISolARImageFilter&gt;(UUID::OPENCV::IMAGE_FILTER);\nSRef&lt;ISolARImageConvertor&gt; imageConvertor = opencvModule.createComponent&lt;ISolARImageConvertor&gt;(UUID::OPENCV::IMAGE_CONVERTOR);\nSRef&lt;ISolARContoursExtractor&gt; contoursExtractor = opencvModule.createComponent&lt;ISolARContoursExtractor&gt;(UUID::OPENCV::CONTOURS_EXTRACTOR);\nSRef&lt;ISolARContoursFilter&gt; contoursFilter = opencvModule.createComponent&lt;ISolARContoursFilter&gt;(UUID::OPENCV::CONTOURS_FILTER_BINARY_MARKER);\nSRef&lt;ISolARPerspectiveController&gt; perspectiveController = opencvModule.createComponent&lt;ISolARPerspectiveController&gt;(UUID::OPENCV::PERSPECTIVE_CONTROLLER);\nSRef&lt;ISolARDescriptorsExtractorSBPattern&gt; patternDescriptorExtractor = opencvModule.createComponent&lt;ISolARDescriptorsExtractorSBPattern&gt;(UUID::OPENCV::DESCRIPTORS_EXTRACTOR_SBPATTERN);\nSRef&lt;ISolARDescriptorMatcher&gt; patternMatcher = opencvModule.createComponent&lt;ISolARDescriptorMatcher&gt;(UUID::OPENCV::DESCRIPTOR_MATCHER_RADIUS);\nSRef&lt;ISolARSBPatternReIndexer&gt; patternReIndexer = opencvModule.createComponent&lt;ISolARSBPatternReIndexer&gt;(UUID::OPENCV::SBPATTERN_REINDEXER);\nSRef&lt;ISolARImage2WorldMapper&gt; img2worldMapper = opencvModule.createComponent&lt;ISolARImage2WorldMapper&gt;(UUID::OPENCV::IMAGE2WORLD_MAPPER);\nSRef&lt;ISolARPoseEstimation&gt; PnP = opencvModule.createComponent&lt;ISolARPoseEstimation&gt;(UUID::OPENCV::POSE_ESTIMATION);\n\n\n\n\nData structures declaration\n\nYour components will exchange data through data structures when running the pipeline. You need to declare all those shown in figure 1.\n\n\nmain.cpp\n\n// ADD HERE: declarations of data structures used to connect components\n// Example to declare a SolARImage:\n// SRef&lt;SolARImage&gt; inputImage;\n\nSRef&lt;SolARImage&gt; inputImage;\nSRef&lt;SolARImage&gt; greyImage  = xpcf::utils::make_shared&lt;SolARImage&gt;(SolARImage::ImageLayout::LAYOUT_GREY,\n                                 SolARImage::PixelOrder::INTERLEAVED,SolARImage::DataType::TYPE_8U); (1)\nSRef&lt;SolARImage&gt; binaryImage  = xpcf::utils::make_shared&lt;SolARImage&gt;(SolARImage::ImageLayout::LAYOUT_GREY,\n                                 SolARImage::PixelOrder::INTERLEAVED,SolARImage::DataType::TYPE_8U); (1)\n\nSRef&lt;SolARImage&gt; contoursImage;\nSRef&lt;SolARImage&gt; filteredContoursImage;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              contours;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              filtered_contours;\nstd::vector&lt;SRef&lt;SolARImage&gt;&gt;                   patches;\nstd::vector&lt;SRef&lt;SolARContour2Df&gt;&gt;              recognizedContours;\nSRef&lt;SolARDescriptorBuffer&gt;                     recognizedPatternsDescriptors;\nSRef&lt;SolARDescriptorBuffer&gt;                     markerPatternDescriptor;\nstd::vector&lt;SolARDescriptorMatch&gt;               patternMatches;\nstd::vector&lt;SRef&lt;SolARPoint2Df&gt;&gt;                pattern2DPoints;\nstd::vector&lt;SRef&lt;SolARPoint2Df&gt;&gt;                img2DPoints;\nstd::vector&lt;SRef&lt;SolARPoint3Df&gt;&gt;                pattern3DPoints;\nSolARPose                                       pose;\n\nSolARCamCalibration K;\nSolARCamDistortion camDist;\n\n\n\n\n\n1\nhere, the image converter and filter do not yet instantiate the output image, so you need to do it yourself.\n\n\n\n\n\nComponents configuration\n\nTo complete\n\n\nmain.cpp\n\n// ADD HERE: Components configuration\n// Generally through the method setParamerters of the components, except for the input components such as the camera or the marker that use specific methods to load configuration files\n\nbinaryMarker-&gt;loadMarker(argv[1]);\npatternDescriptorExtractor-&gt;extract(binaryMarker-&gt;getPattern(), markerPatternDescriptor);\n\nint minContourSize = 4;\ncontoursExtractor-&gt;setParameters(minContourSize);\n\nint minContourLength = 20;\ncontoursFilter-&gt;setParameters(minContourLength);\n\nSolARSizei CorrectedImagesSize = {640,480};\nperspectiveController-&gt;setParameters(CorrectedImagesSize);\n\nint patternSize = binaryMarker-&gt;getPattern()-&gt;getSize();\npatternDescriptorExtractor-&gt;setParameters(patternSize);\n\npatternReIndexer-&gt;setParameters(patternSize);\n\nSolARSizei sbPatternSize;\nsbPatternSize.width = patternSize;\nsbPatternSize.height = patternSize;\nimg2worldMapper-&gt;setParameters(sbPatternSize, binaryMarker-&gt;getSize());\n\n//Load camera parameters and start it\ncamera-&gt;loadCameraParameters(argv[2]);\n\nPnP-&gt;setCameraParameters(camera-&gt;getIntrinsicsParameters(), camera-&gt;getDistorsionParameters());\noverlay3D-&gt;setCameraParameters(camera-&gt;getIntrinsicsParameters(), camera-&gt;getDistorsionParameters());\n\nif (camera-&gt;start(atoi(argv[3])) != FrameworkReturnCode::_SUCCESS) // Camera\n{\n    LOG_ERROR (&quot;Camera with id {} does not exist&quot;, argv[3]);\n    return ;\n}\n\n\n\n\nThe pipeline loop\n\nTo complete\n\n\nmain.cpp\n\nbool process = true;\nwhile (process)\n{\n  if(camera-&gt;getNextImage(inputImage)==SolAR::FrameworkReturnCode::_ERROR_)\n       break;\n\n  // Convert Image from RGB to grey\n  imageConvertor-&gt;convert(inputImage, greyImage);\n\n  // Convert Image from grey to black and white\n  imageFilter-&gt;binarize(greyImage,binaryImage,-1,255);\n\n  // Extract contours from binary image\n  contoursExtractor-&gt;extract(binaryImage,contours);\n\n  // Filter 4 edges contours to find those candidate for marker contours\n  contoursFilter-&gt;filter(contours, filtered_contours);\n\n  // Create one warpped and cropped image by contour\n  perspectiveController-&gt;correct(binaryImage, filtered_contours, patches);\n\n  // test if this last image is really a squared binary marker, and if it is the case, extract its descriptor\n   if (patternDescriptorExtractor-&gt;extract(patches, filtered_contours, recognizedPatternsDescriptors, recognizedContours) != FrameworkReturnCode::_ERROR_)\n   {\n       // From extracted squared binary pattern, match the one corresponding to the squared binary marker\n       if (patternMatcher-&gt;match(markerPatternDescriptor, recognizedPatternsDescriptors, patternMatches) == SolAR::DescriptorMatcher::DESCRIPTORS_MATCHER_OK)\n       {\n\n           // Reindex the pattern to create two vector of points, the first one corresponding to marker corner, the second one corresponding to the poitsn of the contour\n           patternReIndexer-&gt;reindex(recognizedContours, patternMatches, pattern2DPoints, img2DPoints);\n\n           // Compute the 3D position of each corner of the marker\n           img2worldMapper-&gt;map(pattern2DPoints, pattern3DPoints);\n\n           // Compute the pose of the camera using a Perspective n Points algorithm using only the 4 corners of the marker\n           if (PnP-&gt;poseFromSolvePNP(pose, img2DPoints, pattern3DPoints) == FrameworkReturnCode::_SUCCESS)\n           {\n               LOG_INFO(&quot;Pose: {}&quot;, pose);\n           }\n       }\n   }\n}\n\n\n\n\nDisplay a cube\n\nto complete\n\n\n\n\n\n",
      id: 44
    });
    

  

    index.add({
      title: "tools",
      content: "\nTable of Contents\n\nsubmenuconfig\nCamera Calibration Program\n\n\n\nsubmenuconfig\n\n\n\n\ninstallation\n\n\nsamples\n\n\ntutorials\n\n\ntools\n\n\n\n\n\n\nCamera Calibration Program\n\n\nThis example helps you to calibrate your camera and it provides a camera calibration parameters set.\nThese parameters stored in a file can be taken as input by any program to set the intrinsic parameters of your camera.\nRight now, we do not offer a solution for non-calibrated pose pipeline. Natural Marker and Fiducial Marker program samples\nassume you will provide the camera calibration parameters at runtime.\n\n\nIn general, this tool is useful for any program you will create by yourself using SolAR.\n\n\nThe calibration process is based on state of the art method and uses a chessboard.\n\n\nYou can have one while printing the \"chessboard.png\" in this project.\n\n\nThe input file used for this calibration program gives information about how to setup your chessboard: measure the squares on your chessboard sheet, aspect ratio and square size.\n\n\nTo get more details, please read the readme.adoc file that you can find in the camera calibration folder.\n\n\nlink: http://forge.b-com.com/git/argo/SolAR/Samples/CameraCalibration.git\n\n\n\n\n\n\n\n\n\nIf you use QT creator, open the .pro file and configure your project as usual (see \"getting started\").\n\n\nHave a look at the \".cpp\" file, which is clearly commented and explained step by step.\n\n\n2 files are used :\n\n\n\n\ncalibration_config.yml, which is an input file\n\n\ncamera_calibration.yml, which is an output file (but can be used as input file for other programs)\n\n\n\n\n=== Fiducial Marker samples\n\n\nHere is an example of Fiducial Image Marker based on SolAR.\n\n\nFor the three versions of it, you can see a visual feedback of natural marker estimation.  As for Natural Image, you can choose simple, static or dynamic mode (the differences are the same as for natural markers).\n\n\n\n\n",
      id: 45
    });
    

  



var store = [];

  
store.push({"title": "API",
  "link": "https://solarframework.github.io///API.html"
});

  
store.push({"title": "Community",
  "link": "https://solarframework.github.io///community.html"
});

  
store.push({"title": "Contribute",
  "link": "https://solarframework.github.io///contribute.html"
});

  
store.push({"title": "Discover",
  "link": "https://solarframework.github.io///discover.html"
});

  
store.push({"title": null,
  "link": "https://solarframework.github.io///feed.xml"
});

  
store.push({"title": "welcome",
  "link": "https://solarframework.github.io///"
});

  
store.push({"title": "Knowledge",
  "link": "https://solarframework.github.io///knowledge.html"
});

  
store.push({"title": null,
  "link": "https://solarframework.github.io///js/lunr-feed.js"
});

  
store.push({"title": "Made with SolAR",
  "link": "https://solarframework.github.io///made_with_solAR.html"
});

  
store.push({"title": "package &amp; download third parties",
  "link": "https://solarframework.github.io///argodoc/packageanddownload.html"
});

  
store.push({"title": "Search",
  "link": "https://solarframework.github.io///search.html"
});

  
store.push({"title": "Tags",
  "link": "https://solarframework.github.io///tags.html"
});

  
store.push({"title": "Use it",
  "link": "https://solarframework.github.io///use_it.html"
});



  
  
  

  
  
  
    
    store.push({"title": "Acquisition",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Acquisition/"
    });
  
    
    store.push({"title": "Conversion",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Conversion/"
    });
  
    
    store.push({"title": "Estimation",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Estimation/"
    });
  
    
    store.push({"title": "Features",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Features/"
    });
  
    
    store.push({"title": "Filtering",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Filtering/"
    });
  
    
    store.push({"title": "Image",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Image/"
    });
  
    
    store.push({"title": "Optimization",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/Optimization/"
    });
  
    
    store.push({"title": "Poseestimation",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/PoseEstimation/"
    });
  
    
    store.push({"title": "Thirdpartyconnector",
      "link": "https://solarframework.github.io///contribute/ComponentInterfaceDescription/ThirdPartyConnector/"
    });
  
    
    store.push({"title": "Features",
      "link": "https://solarframework.github.io///contribute/DataStructureDescription/Features/"
    });
  
    
    store.push({"title": "Image",
      "link": "https://solarframework.github.io///contribute/DataStructureDescription/Image/"
    });
  
    
    store.push({"title": "Markers",
      "link": "https://solarframework.github.io///contribute/DataStructureDescription/Markers/"
    });
  
    
    store.push({"title": "Matrix",
      "link": "https://solarframework.github.io///contribute/DataStructureDescription/Matrix/"
    });
  
    
    store.push({"title": "Pose",
      "link": "https://solarframework.github.io///contribute/DataStructureDescription/Pose/"
    });
  
    
    store.push({"title": "how it works",
      "link": "https://solarframework.github.io///contribute/how_it_works/"
    });
  
    
    store.push({"title": "getting started",
      "link": "https://solarframework.github.io///contribute/getting_started/"
    });
  
    
    store.push({"title": "create a component",
      "link": "https://solarframework.github.io///contribute/create_component/"
    });
  
    
    store.push({"title": "contribute to core",
      "link": "https://solarframework.github.io///contribute/contribute_to_core/"
    });
  
    
    store.push({"title": "best practices",
      "link": "https://solarframework.github.io///contribute/best_practices/"
    });
  
    
    store.push({"title": "contribution workflow",
      "link": "https://solarframework.github.io///contribute/github_workflow/"
    });
  
    
    store.push({"title": "tools",
      "link": "https://solarframework.github.io///contribute/tools/"
    });
  

  
  
  
    
    store.push({"title": "what",
      "link": "https://solarframework.github.io///discover/what/"
    });
  
    
    store.push({"title": "how",
      "link": "https://solarframework.github.io///discover/how/"
    });
  
    
    store.push({"title": "who",
      "link": "https://solarframework.github.io///discover/who/"
    });
  
    
    store.push({"title": "when",
      "link": "https://solarframework.github.io///discover/when/"
    });
  
    
    store.push({"title": "for whom",
      "link": "https://solarframework.github.io///discover/for_whom/"
    });
  
    
    store.push({"title": "programmer's guide",
      "link": "https://solarframework.github.io///discover/programmer_guide/"
    });
  
    
    store.push({"title": "legal notice",
      "link": "https://solarframework.github.io///discover/legal_notice/"
    });
  

  
  
  

  
  
  
    
    store.push({"title": "Fiducialmarker",
      "link": "https://solarframework.github.io///use_it/tutorials/FiducialMarker/fiducialMarker/"
    });
  
    
    store.push({"title": "installation",
      "link": "https://solarframework.github.io///use_it/downloads/"
    });
  
    
    store.push({"title": "samples",
      "link": "https://solarframework.github.io///use_it/samples/"
    });
  
    
    store.push({"title": "tutorials",
      "link": "https://solarframework.github.io///use_it/tutorials/"
    });
  
    
    store.push({"title": "tools",
      "link": "https://solarframework.github.io///use_it/tools/"
    });
  


function searchAndDisplay(query){
  var resultdiv = $('#results');
  var result = index.search(query);
  // Show results
  resultdiv.empty();
  // Add status
  resultdiv.prepend('<p class="">Found '+result.length+' result(s)</p>');
  // Loop through, match, and add results
  for (var item in result) {
    var ref = result[item].ref;
    var searchitem = '<div class="result"><div class="result-body"><li><a href="'+store[ref].link+'" class="post-title">'+store[ref].title+'</a></li></div>';
    resultdiv.append(searchitem);
  }
}

// builds search
$(document).ready(function() {
    var query = (decodeURI(location.search).split("q" + '=')[1] || '').split('&')[0];
    var formattedQuery = query.split("+").join(" ");
    searchAndDisplay(formattedQuery);

    $('input#search').on('keyup', function () {
      var query = $(this).val();
      searchAndDisplay(query);
    });
});
